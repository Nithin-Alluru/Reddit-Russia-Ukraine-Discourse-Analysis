{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbcf5eab355dc041",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a421db0752fd0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:26:56.031453Z",
     "start_time": "2025-05-07T01:26:52.069151Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "RANDOM_STATE = 5664\n",
    "def load_network(edge_list_file):\n",
    "    \"\"\"\n",
    "    Load a network from an edge list file.\n",
    "    \n",
    "    Args:\n",
    "        edge_list_file (str): Path to the edge list file\n",
    "        \n",
    "    Returns:\n",
    "        networkx.Graph: The loaded network graph\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if file exists and has content\n",
    "        if not os.path.exists(edge_list_file) or os.path.getsize(edge_list_file) == 0:\n",
    "            raise FileNotFoundError(f\"Edge list file not found or empty: {edge_list_file}\")\n",
    "        \n",
    "        # Load the network\n",
    "        G = nx.read_edgelist(edge_list_file)\n",
    "        print(f\"Network loaded from {edge_list_file}\")\n",
    "        print(f\"  Number of nodes: {G.number_of_nodes()}\")\n",
    "        print(f\"  Number of edges: {G.number_of_edges()}\")\n",
    "        print(f\"\\tNetwork density: {nx.density(G):.4f}\")      \n",
    "        \n",
    "        return G\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in load_network: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Load the network\n",
    "edge_list_file_vec = \"network_similarity_vec.csv\"\n",
    "G = load_network(edge_list_file_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addcfcd2ad3d67e6",
   "metadata": {},
   "source": [
    "## Degree Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7cd058f0feec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:26:56.106657Z",
     "start_time": "2025-05-07T01:26:56.060958Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Small world and heavy-tail analysis\n",
    "\n",
    "degree_sequence = sorted((d for n, d in G.degree()), reverse=True)\n",
    "print(\"Basic degree statistics:\")\n",
    "print(f\"\\tTotal degree: {sum(degree_sequence)}\")\n",
    "print(f\"\\tMinimum degree: {np.min(degree_sequence)}\")\n",
    "print(f\"\\tMaximum degree: {np.max(degree_sequence)}\")\n",
    "print(f\"\\tMean degree: {np.mean(degree_sequence):.2f}\")\n",
    "print(f\"\\tMedian degree: {np.median(degree_sequence)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae6cd48fd78058f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:27:01.813038Z",
     "start_time": "2025-05-07T01:26:57.716068Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_degree_sequence(degrees):\n",
    "    fig = plt.figure(\"Degree Distribution Analysis\", figsize=(8, 8))\n",
    "    axgrid = fig.add_gridspec(3, 2)\n",
    "    \n",
    "    # Subplot 1: Degree rank plot\n",
    "    ax1 = fig.add_subplot(axgrid[0, 0])\n",
    "    ax1.loglog(degrees, \"b-\", marker=\"o\")\n",
    "    ax1.set_title(\"Degree Rank Plot\")\n",
    "    ax1.set_ylabel(\"Degree\")\n",
    "    ax1.set_xlabel(\"Rank\")\n",
    "    \n",
    "    # Subplot 2: Degree histogram\n",
    "    ax2 = fig.add_subplot(axgrid[1, 0])\n",
    "    ax2.hist(degrees, bins=100, log=True)\n",
    "    ax2.set_title(\"Degree Histogram\")\n",
    "    ax2.set_xlabel(\"Degree\")\n",
    "    ax2.set_ylabel(\"# of Nodes\")\n",
    "    \n",
    "    # Subplot 3: Degree Log Scale\n",
    "    ax3 = fig.add_subplot(axgrid[0, 1])\n",
    "    ax3.loglog(*np.unique(degrees, return_counts=True))\n",
    "    ax3.set_title(\"Degree Histogram - Log-Log\")\n",
    "    ax3.set_xlabel(\"Degree\")\n",
    "    ax3.set_ylabel(\"# of Nodes\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "plot_degree_sequence(degree_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03ad675153c8af6",
   "metadata": {},
   "source": [
    "## Connected Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3856971c1fdbbb99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:27:02.132685Z",
     "start_time": "2025-05-07T01:27:01.825766Z"
    }
   },
   "outputs": [],
   "source": [
    "def giant_network_analysis(G):\n",
    "    \"\"\"\n",
    "    Perform basic analysis on a network graph.\n",
    "    \n",
    "    Args:\n",
    "        G (networkx.Graph): The network graph to analyze\n",
    "        \n",
    "    Returns:\n",
    "        networkx.Graph: The analyzed network graph\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\nNetwork Analysis:\")\n",
    "\n",
    "        # Connected components analysis\n",
    "        num_components = nx.number_connected_components(G)\n",
    "        print(f\"  Number of connected components: {num_components}\")\n",
    "        \n",
    "        largest_cc = None\n",
    "        if num_components > 0:\n",
    "            # Get largest connected component\n",
    "            largest_cc = max(nx.connected_components(G), key=len)\n",
    "            largest_cc_size = len(largest_cc)\n",
    "            print(f\"  Size of largest connected component: {largest_cc_size} nodes\")\n",
    "            print(f\"  Percentage of nodes in largest component: {largest_cc_size/G.number_of_nodes()*100:.2f}%\")\n",
    "        \n",
    "        return largest_cc\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in analyze_network: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Analyze the network\n",
    "Giant = giant_network_analysis(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cfe5a2d15f59a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:10.863164Z",
     "start_time": "2025-05-07T01:27:02.160672Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "g_cc = G.subgraph(Giant).copy()\n",
    "shortest_path_avg = nx.average_shortest_path_length(g_cc)\n",
    "print(f\"Average shortest path in the giant component: {shortest_path_avg}\")\n",
    "diameter = nx.diameter(g_cc)\n",
    "print(f\"Diameter of the giant component: {diameter}\")\n",
    "# 29 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caed4428c14ac2d9",
   "metadata": {},
   "source": [
    "## Centrality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98380ffc469db3e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:10.927714Z",
     "start_time": "2025-05-07T01:56:10.923703Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up parallelization (use latest nx version, also install nx-parallel)\n",
    "nx.config.backends.parallel.active = True\n",
    "nxp_config = nx.config.backends.parallel\n",
    "nxp_config.n_jobs = 8\n",
    "nxp_config.verbose = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c062728617127",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centrality = nx.degree_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G, normalized=True, backend=\"parallel\")\n",
    "# Take a sample of closeness and discuss the distribution\n",
    "sample = random.sample(list(G.nodes), 1000)\n",
    "closeness_centrality = {node: nx.closeness_centrality(G, node) for node in sample} # 2 minutes to run\n",
    " \n",
    "\n",
    "top_5_degree = sorted(degree_centrality.items(),  key=lambda x: x[1], reverse=True)[:5]\n",
    "top_5_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "top_5_closeness = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "print(\"Top 5 Nodes by Degree Centrality:\", top_5_degree)\n",
    "print(\"Top 5 Nodes by Betweenness Centrality:\", top_5_betweenness)\n",
    "print(\"Top 5 Nodes by Closeness Centrality:\", top_5_closeness)\n",
    "\n",
    "# 8 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7cd092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_centrality_distributions(degree_centrality, betweenness_centrality, closeness_centrality):\n",
    "    \"\"\"\n",
    "    Plot the distributions of Degree Centrality, Betweenness Centrality, and Closeness Centrality.\n",
    "    \"\"\"\n",
    "    # Convert centrality values to lists for plotting\n",
    "    degree_values = list(degree_centrality.values())\n",
    "    betweenness_values = list(betweenness_centrality.values())\n",
    "    closeness_values = list(closeness_centrality.values())\n",
    "\n",
    "    # plotting style\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=False)\n",
    "\n",
    "    # Degree Centrality Distribution\n",
    "    sns.histplot(degree_values, bins=50, color=\"skyblue\", ax=axes[0])\n",
    "    axes[0].set_title(\"Degree Centrality Distribution\", fontsize=14)\n",
    "    axes[0].set_xlabel(\"Degree Centrality\", fontsize=12)\n",
    "    axes[0].set_ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "    # Betweenness Centrality Distribution\n",
    "    sns.histplot(betweenness_values, bins=50, color=\"orange\", ax=axes[1])\n",
    "    axes[1].set_title(\"Betweenness Centrality Distribution\", fontsize=14)\n",
    "    axes[1].set_xlabel(\"Betweenness Centrality\", fontsize=12)\n",
    "    axes[1].set_ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "    # Closeness Centrality Distribution\n",
    "    sns.histplot(closeness_values, bins=50, color=\"green\", ax=axes[2])\n",
    "    axes[2].set_title(\"Closeness Centrality Distribution\", fontsize=14)\n",
    "    axes[2].set_xlabel(\"Closeness Centrality\", fontsize=12)\n",
    "    axes[2].set_ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the distributions\n",
    "plot_centrality_distributions(degree_centrality, betweenness_centrality, closeness_centrality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de375e563dd5bfb",
   "metadata": {},
   "source": [
    "## Clustering analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0231cde32bb3c86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T02:08:46.134002Z",
     "start_time": "2025-05-07T02:05:29.912606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clustering coefficient for each node\n",
    "clustering_coeffs = nx.clustering(G)\n",
    "\n",
    "# average clustering coefficient\n",
    "avg_clustering = nx.average_clustering(G)\n",
    "\n",
    "# Compute global clustering coefficient\n",
    "global_clustering = nx.transitivity(G)\n",
    "\n",
    "# Print results\n",
    "print(f\"Minimum Clustering Coefficient: {min(clustering_coeffs.values())}\")\n",
    "print(f\"Maximum Clustering Coefficient: {max(clustering_coeffs.values())}\")\n",
    "print(f\"Average Clustering Coefficient: {avg_clustering:.6f}\")\n",
    "print(f\"Global Clustering Coefficient: {global_clustering:.6f}\")\n",
    "\n",
    "# 3 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d82df663d0e894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T02:11:55.643443Z",
     "start_time": "2025-05-07T02:10:22.493054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generating Watts-Strogatz small-world network\n",
    "WS_graph = nx.watts_strogatz_graph(G.number_of_nodes(), round(np.mean(degree_sequence)), 0.1)\n",
    "\n",
    "# Computing metrics for Watts-Strogatz model\n",
    "ws_avg_clustering = nx.average_clustering(WS_graph)\n",
    "ws_global_clustering = nx.transitivity(WS_graph)\n",
    "ws_avg_shortest_path = nx.average_shortest_path_length(WS_graph)\n",
    "\n",
    "# Print comparison\n",
    "print(f\"Average Clustering Coefficient Watts-Strogatz: {ws_avg_clustering:.4f}\")\n",
    "print(f\"Global Clustering Coefficient Watts-Strogatz: {ws_global_clustering:.4f}\")\n",
    "print(f\"Average Shortest Path Length Watts-Strogatz: {ws_avg_shortest_path:.4f}\")\n",
    "\n",
    "# 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5bb18969f2868",
   "metadata": {},
   "source": [
    "## Small World Property Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3c5b897f842cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T02:12:20.933720Z",
     "start_time": "2025-05-07T02:12:20.927736Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Network shortest average path: {shortest_path_avg:.4f}\")\n",
    "print(f\"Average Clustering Coefficient: {avg_clustering:.6f}\")\n",
    "print(f\"Global Clustering Coefficient: {global_clustering:.6f}\")\n",
    "\n",
    "print(f\"Average Clustering Coefficient Watts-Strogatz: {ws_avg_clustering:.4f}\")\n",
    "print(f\"Global Clustering Coefficient Watts-Strogatz: {ws_global_clustering:.4f}\")\n",
    "print(f\"Average Shortest Path Length Watts-Strogatz: {ws_avg_shortest_path:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64faf3e61f7a8cf",
   "metadata": {},
   "source": [
    "## Modularity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38d456b252c9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T02:14:27.198907Z",
     "start_time": "2025-05-07T02:14:13.996682Z"
    }
   },
   "outputs": [],
   "source": [
    "from community import community_louvain as community\n",
    "dendrogram = community.generate_dendrogram(G, random_state = RANDOM_STATE)\n",
    "for level in range(len(dendrogram)):\n",
    "    partition = community.partition_at_level(dendrogram, level)\n",
    "    modularity = community.modularity(partition, G)\n",
    "    \n",
    "    print(f\"Level {level}: Modularity = {modularity}, Number of Partitions = {len(set(partition.values()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830f11f1",
   "metadata": {},
   "source": [
    "## Graph Clustering & Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a75c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import matplotlib.pyplot as plt\n",
    "# Plotting the hierarchial organisation of the communities 'Deddrogram'.\n",
    "pg = nx.DiGraph()\n",
    "\n",
    "last_part = None\n",
    "for l, part in enumerate(dendrogram):\n",
    "    print(l, len(part))\n",
    "    for n, comm in part.items():\n",
    "        # level = ?, community = ?\n",
    "        nom = \"l={}_{}\".format(l, comm)\n",
    "        pg.add_node(nom, comm=comm, color=l+1)\n",
    "\n",
    "        if l == 0:\n",
    "            pg.add_node(n, comm=comm, color=0)\n",
    "            pg.add_edge(nom, n)\n",
    "        else: \n",
    "            pg.add_edge(nom, \"l={}_{}\".format(l-1, n))\n",
    "    last_part = part\n",
    "   \n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "colors = list(nx.get_node_attributes(pg, 'color').values())\n",
    "\n",
    "pos = graphviz_layout(pg, prog='dot')\n",
    "nx.draw(pg, pos, with_labels=True, arrows=False, node_color=colors, vmin=0, vmax=len(dendrogram) + 1, cmap=plt.cm.tab20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the best partition for cluster analysis.\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "partition = community.best_partition(G)\n",
    "\n",
    "#drawing\n",
    "size = float(len(set(partition.values())))\n",
    "pos = nx.spring_layout(G, seed=RANDOM_STATE)\n",
    "node_list = [n for n, n_com in sorted(partition.items())]\n",
    "node_colors = [n_com for n, n_com in sorted(partition.items())]\n",
    "    \n",
    "nx.draw_networkx_nodes(G, pos, node_list, node_size=40, \n",
    "                       # the arguments below here make each community a different color\n",
    "                       vmin=0, vmax=size,\n",
    "                       node_color=node_colors, cmap=plt.cm.tab20)\n",
    "    #print(count)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0936ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 largest clusters' analysis.\n",
    "\n",
    "import networkx as nx\n",
    "import community\n",
    "from collections import Counter\n",
    "\n",
    "best_partition = community.best_partition(G, random_state=RANDOM_STATE)\n",
    "\n",
    "community_sizes = Counter(best_partition.values())\n",
    "\n",
    "# 3 largest communities\n",
    "top_communities = [com for com, size in community_sizes.most_common(3)]\n",
    "\n",
    "# Create subgraphs\n",
    "subgraphs = {com: G.subgraph([node for node, c in best_partition.items() if c == com]) for com in top_communities}\n",
    "\n",
    "# statistics\n",
    "for com, subgraph in subgraphs.items():\n",
    "    num_nodes = subgraph.number_of_nodes()\n",
    "    num_edges = subgraph.number_of_edges()\n",
    "    density = nx.density(subgraph)\n",
    "    avg_degree = sum(dict(subgraph.degree()).values()) / num_nodes\n",
    "    clustering_coeff = nx.average_clustering(subgraph)\n",
    "    \n",
    "    betweenness = nx.betweenness_centrality(subgraph, normalized=True)\n",
    "    avg_betweenness = sum(betweenness.values()) / num_nodes\n",
    "\n",
    "    print(f\"Community {com}:\")\n",
    "    print(f\"- Nodes: {num_nodes}\")\n",
    "    print(f\"- Edges: {num_edges}\")\n",
    "    print(f\"- Density: {density:.4f}\")\n",
    "    print(f\"- Average Degree: {avg_degree:.2f}\")\n",
    "    print(f\"- Clustering Coefficient: {clustering_coeff:.4f}\")\n",
    "    print(f\"- Average Betweenness Centrality: {avg_betweenness:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14cb44f",
   "metadata": {},
   "source": [
    "## Finding k-Cliques (CPM Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdeb087",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = nx.depth_first_search.dfs_tree(G, '1', 4)\n",
    "sg = G.subgraph(sg.nodes)\n",
    "\n",
    "k_values = [3, 4, 5]\n",
    "\n",
    "# Initialize subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "pos = nx.spring_layout(sg, seed=RANDOM_STATE)\n",
    "\n",
    "for i, k in enumerate(k_values):\n",
    "    communities = list(nx.community.k_clique_communities(sg, k))\n",
    "    \n",
    "    node_colors = {}\n",
    "    for j, community in enumerate(communities):\n",
    "        for node in community:\n",
    "            node_colors[node] = j \n",
    "    # color list\n",
    "    colors = [node_colors.get(node, -1) for node in sg.nodes()]\n",
    "    \n",
    "    ax = axes[i]\n",
    "    nx.draw(sg, pos, ax=ax, node_color=colors, cmap=plt.cm.tab20, with_labels=False, node_size=50, edge_color=\"gray\")\n",
    "    ax.set_title(f\"k = {k} (Communities: {len(communities)})\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
