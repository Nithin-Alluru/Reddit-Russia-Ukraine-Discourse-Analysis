{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Dataset",
   "id": "cbcf5eab355dc041"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T23:17:59.365371Z",
     "start_time": "2025-05-01T23:13:27.038746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "def load_network(edge_list_file):\n",
    "    \"\"\"\n",
    "    Load a network from an edge list file.\n",
    "    \n",
    "    Args:\n",
    "        edge_list_file (str): Path to the edge list file\n",
    "        \n",
    "    Returns:\n",
    "        networkx.Graph: The loaded network graph\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if file exists and has content\n",
    "        if not os.path.exists(edge_list_file) or os.path.getsize(edge_list_file) == 0:\n",
    "            raise FileNotFoundError(f\"Edge list file not found or empty: {edge_list_file}\")\n",
    "        \n",
    "        # Load the network\n",
    "        G = nx.read_edgelist(edge_list_file)\n",
    "        print(f\"Network loaded from {edge_list_file}\")\n",
    "        print(f\"  Number of nodes: {G.number_of_nodes()}\")\n",
    "        print(f\"  Number of edges: {G.number_of_edges()}\")\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in load_network: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Load the network\n",
    "edge_list_file_vec = \"./network_similarity_vec.txt\"\n",
    "G = load_network(edge_list_file_vec)"
   ],
   "id": "49a421db0752fd0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network loaded from ./network_similarity_vec.txt\n",
      "  Number of nodes: 35596\n",
      "  Number of edges: 58059686\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analyze Network",
   "id": "b03ad675153c8af6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T23:42:17.031315Z",
     "start_time": "2025-05-01T23:39:09.754590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_network(G):\n",
    "    \"\"\"\n",
    "    Perform basic analysis on a network graph.\n",
    "    \n",
    "    Args:\n",
    "        G (networkx.Graph): The network graph to analyze\n",
    "        \n",
    "    Returns:\n",
    "        networkx.Graph: The analyzed network graph\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\nNetwork Analysis:\")\n",
    "        \n",
    "        # Connected components analysis\n",
    "        num_components = nx.number_connected_components(G)\n",
    "        print(f\"  Number of connected components: {num_components}\")\n",
    "        \n",
    "        largest_cc = None\n",
    "        if num_components > 0:\n",
    "            # Get largest connected component\n",
    "            largest_cc = max(nx.connected_components(G), key=len)\n",
    "            largest_cc_size = len(largest_cc)\n",
    "            print(f\"  Size of largest connected component: {largest_cc_size} nodes\")\n",
    "            print(f\"  Percentage of nodes in largest component: {largest_cc_size/G.number_of_nodes()*100:.2f}%\")\n",
    "        \n",
    "        return G, largest_cc\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in analyze_network: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Analyze the network\n",
    "G, Giant = analyze_network(G)"
   ],
   "id": "3856971c1fdbbb99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network Analysis:\n",
      "  Number of connected components: 62\n",
      "  Size of largest connected component: 7960 nodes\n",
      "  Percentage of nodes in largest component: 22.36%\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: add all stat analysis to analyze_network\n",
    "# TODO: Make methods for centrality, etc"
   ],
   "id": "7f27e410ce08933b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T00:08:53.624792Z",
     "start_time": "2025-05-02T00:03:33.879473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g_cc = G.subgraph(Giant).copy()\n",
    "print(\"Giant graph made\")\n",
    "\n",
    "# Network diameter\n",
    "diameter = nx.diameter(g_cc)\n",
    "print(f\"Network diameter: {diameter:.4f}\")\n",
    "\n",
    "# 6 minutes to make g_cc\n",
    "# Cell finishes in "
   ],
   "id": "75cfe5a2d15f59a4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Network density\n",
    "density = nx.density(G)\n",
    "print(f\"Network density: {density:.4f}\")\n",
    "\n",
    "# Network shortest path\n",
    "shortest_path_avg = nx.average_shortest_path_length(G)\n",
    "print(f\"Network shortest average path: {shortest_path_avg:.4f}\")"
   ],
   "id": "e2022991babaa0d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Centrality Analysis",
   "id": "caed4428c14ac2d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "degree_centralities = nx.degree_centrality(G)\n",
    "closeness_centralities = nx.closeness_centrality(G)\n",
    "betweenness_centralities = nx.betweenness_centrality(G)\n",
    "\n",
    "# TODO: make graphs"
   ],
   "id": "a173d7e6b53cc323"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Clustering analysis",
   "id": "9de375e563dd5bfb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(nx.average_clustering(G))\n",
    "clustering_coefficients = nx.clustering(G)\n",
    "\n",
    "print(min(clustering_coefficients.values()))\n",
    "print(max(clustering_coefficients.values()))"
   ],
   "id": "f0231cde32bb3c86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Degree Distribution Analysis",
   "id": "addcfcd2ad3d67e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Small world and heavy-tail analysis\n",
    "\n",
    "degrees = dict(nx.degree(G))\n",
    "print(sum(degrees.values())) # Total degree\n",
    "print(sum(degrees.values())/nx.number_of_nodes(G)) # Average degree\n",
    "\n",
    "degree_sequence = sorted(degrees.values(), reverse=True)\n",
    "# TODO: plot degree sequences"
   ],
   "id": "e6c7cd058f0feec3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.loglog(degree_sequence,'b-',marker='o')\n",
    "plt.title('Degree rank plot (loglog)')\n",
    "plt.ylabel('Degree')\n",
    "plt.xlabel('Rank')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(degree_sequence,'b-',marker='o')\n",
    "plt.title('Degree rank plot (linear)')\n",
    "plt.ylabel('Degree')\n",
    "plt.xlabel('Rank')\n",
    "plt.show()"
   ],
   "id": "bae6cd48fd78058f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Model Comparison",
   "id": "7c5c184c1b9d035f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
