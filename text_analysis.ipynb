{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189120c123e833e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T20:39:53.399408Z",
     "start_time": "2025-05-06T20:39:53.390419Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get preprocessing methods from make_network.ipynb to keep consistent.\n",
    "RANDOM_STATE = 5664\n",
    "import os\n",
    "import pandas as pd\n",
    "def load_and_clean_data(filepath):\n",
    "    \"\"\"\n",
    "    Load Reddit data and remove duplicate user-subreddit combinations.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the CSV data file\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Cleaned dataframe with unique user-subreddit combinations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(filepath):\n",
    "            raise FileNotFoundError(f\"Data file not found: {filepath}\")\n",
    "            \n",
    "        # Load the dataset\n",
    "        print(f\"Loading data from {filepath}...\")\n",
    "        df = pd.read_csv(filepath)\n",
    "        print(f\"Original data shape: {df.shape}\")\n",
    "        \n",
    "        # Remove exact duplicates\n",
    "        df_unique = df.drop_duplicates().copy()\n",
    "        \n",
    "        print(f\"Data shape after removing exact duplicates: {df_unique.shape}\")\n",
    "        \n",
    "        return df_unique\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in load_and_clean_data: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "def analyze_post_dates(df):\n",
    "    # Convert post_created_time to datetime\n",
    "    df['post_created_time'] = pd.to_datetime(df['post_created_time'])\n",
    "    \n",
    "    # Get the earliest and latest dates\n",
    "    min_date = df['post_created_time'].min()\n",
    "    max_date = df['post_created_time'].max()\n",
    "    \n",
    "    return min_date, max_date\n",
    "\n",
    "def filter_by_date(df, start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Filter dataframe to include only posts within a specific date range.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame with 'post_created_time' column\n",
    "        start_date (str, datetime, optional): Keep posts on or after this date\n",
    "        end_date (str, datetime, optional): Keep posts on or before this date\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Filtered dataframe\n",
    "    \"\"\"\n",
    "    # Make sure post_created_time is datetime\n",
    "    if not pd.api.types.is_datetime64_dtype(df['post_created_time']):\n",
    "        df['post_created_time'] = pd.to_datetime(df['post_created_time'])\n",
    "    \n",
    "    original_count = len(df)\n",
    "    \n",
    "    # Apply date filters\n",
    "    if start_date is not None:\n",
    "        if isinstance(start_date, str):\n",
    "            start_date = pd.to_datetime(start_date)\n",
    "        df = df[df['post_created_time'] >= start_date]\n",
    "    \n",
    "    if end_date is not None:\n",
    "        if isinstance(end_date, str):\n",
    "            end_date = pd.to_datetime(end_date)\n",
    "        df = df[df['post_created_time'] <= end_date]\n",
    "    \n",
    "    # Report on filtering\n",
    "    print(f\"Date filtering:\")\n",
    "    if start_date is not None:\n",
    "        print(f\"  Start date: {start_date}\")\n",
    "    if end_date is not None:\n",
    "        print(f\"  End date: {end_date}\")\n",
    "    print(f\"  Original records: {original_count}\")\n",
    "    print(f\"  Filtered records: {len(df)} ({len(df)/original_count*100:.1f}% retained)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16770055ed9fabad",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T20:41:24.296243Z",
     "start_time": "2025-05-06T20:39:53.420549Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from reddit_opinion_ru_ua.csv...\n",
      "Original data shape: (5168018, 24)\n",
      "Data shape after removing exact duplicates: (5168018, 24)\n",
      "Date filtering:\n",
      "  Start date: 2025-04-19 11:00:47\n",
      "  Original records: 5168018\n",
      "  Filtered records: 95660 (1.9% retained)\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "df_clean = load_and_clean_data(\"reddit_opinion_ru_ua.csv\")\n",
    "min_date, max_date = analyze_post_dates(df_clean)\n",
    "cutoff_date = max_date - timedelta(days=10)\n",
    "\n",
    "df_recent = filter_by_date(df_clean, start_date=cutoff_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce2289a8e5840c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T20:41:26.048905Z",
     "start_time": "2025-05-06T20:41:25.939671Z"
    }
   },
   "outputs": [],
   "source": [
    "todrop = [\"comment_id\", \"created_time\",\"post_id\",\"user_is_verified\",\"user_account_created_time\", \"user_awardee_karma\", \"user_awarder_karma\", \"user_comment_karma\", \"user_link_karma\", \"post_created_time\"]\n",
    "df_recent.drop(todrop, axis=1).copy()\n",
    "df_recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce1e145d402330",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T20:43:41.610856Z",
     "start_time": "2025-05-06T20:43:41.572138Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get basic information\n",
    "print(\"Number of posts:\", len(df_recent))\n",
    "print(\"All subreddits:\")\n",
    "pd.DataFrame(df_recent.subreddit.explode().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3abd9af5e25d4ea",
   "metadata": {},
   "source": [
    "## Set up for topic modeling and sentiment analysis for comments, posts, and post titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ce9e99aa141aca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T20:43:48.000628Z",
     "start_time": "2025-05-06T20:43:44.507995Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "def preprocess_one_doc(text: str, lower: bool, punct: bool, stop: bool, stem: bool):\n",
    "    puncts = set(string.punctuation)\n",
    "    puncts.add(\"...\") # punct does not contain ellipses\n",
    "    puncts.add(\"…\")\n",
    "    puncts.add(\"===\")\n",
    "    puncts.add(\"—\")\n",
    "    puncts.add(\"–\")\n",
    "    puncts.add(\"“\")\n",
    "    puncts.add(\"”\")\n",
    "    puncts.add(\"’\")\n",
    "    puncts.add(\"‘\")\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    # stops.add(\"\")\n",
    "    \n",
    "    \n",
    "    # Lowercase the words depending on sentiment or topic modeling\n",
    "    if lower:\n",
    "        step0 = text.lower()\n",
    "    else:\n",
    "        step0 = text\n",
    "    step1 = word_tokenize(step0)\n",
    "    \n",
    "    \n",
    "    if punct:\n",
    "        step2 = \"\".join([ch for ch in \" \".join(step1) if ch not in puncts]).split()\n",
    "    else:\n",
    "        step2 = step1\n",
    "        \n",
    "        \n",
    "    \n",
    "    if stop:\n",
    "        # Remove stopwords\n",
    "        step3 = [token for token in step2\n",
    "                    if token not in stops # drop stopwords\n",
    "                    # and len(token) > 2 # drop words of insignificant length\n",
    "                    and (not token.startswith(\"http\"))] # drop links\n",
    "    else:\n",
    "        step3 = step2\n",
    "        \n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        step4 = [stemmer.stem(i) for i in step3]\n",
    "    else:\n",
    "        step4 = step3\n",
    "        \n",
    "    return step4\n",
    "\n",
    "from gensim import corpora, models\n",
    "\n",
    "def make_dictionary(alltexts):\n",
    "    d = corpora.Dictionary(alltexts)\n",
    "    d.filter_extremes(no_below=5, no_above=0.3) # Keep words that are in more than 5 documents, but not in more than a third of all documents\n",
    "    d.compactify()\n",
    "    return d\n",
    "\n",
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = RANDOM_STATE\n",
    "\n",
    "def filter_english(text):\n",
    "    try:\n",
    "        return detect(text) == \"en\"\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def clean_column(df, text_column_name):\n",
    "    # Drop all missing values\n",
    "    dfc = df.copy()\n",
    "    dfc.dropna(subset=[text_column_name], inplace=True)\n",
    "    \n",
    "    # Filter non-english text\n",
    "    is_english = dfc[text_column_name].apply(filter_english)\n",
    "    dfc = dfc[is_english]\n",
    "    return dfc\n",
    "\n",
    "def make_all_components(df, text_column_name):\n",
    "    dfc = clean_column(df, text_column_name)\n",
    "    \n",
    "    # Create with standard preprocessing\n",
    "    preprocessed = dfc[text_column_name].apply(lambda x: preprocess_one_doc(x, lower=True, stop=True, punct=True, stem=True)) # Preprocess all docs\n",
    "    dictionary = make_dictionary(preprocessed.tolist()) # Use list of lists of strings\n",
    "    corpus = [dictionary.doc2bow(text) for text in preprocessed.tolist()] # bag of words representation of documents\n",
    "    return preprocessed, dictionary, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55303aacf345955",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-06T20:43:48.005635Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Create with standard preprocessing\n",
    "preprocessed_comments, dictionary_comments, corpus_comments = make_all_components(df_recent, \"self_text\")\n",
    "preprocessed_post_content, dictionary_post_content, corpus_post_content = make_all_components(df_recent, \"post_self_text\")\n",
    "preprocessed_title, dictionary_title, corpus_title = make_all_components(df_recent, \"post_title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8147f7807cbddb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T20:44:40.472864Z",
     "start_time": "2025-05-04T23:21:06.487963Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessed_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf9da0fb2263625",
   "metadata": {},
   "source": [
    "## Evaluate to find best number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc8ece3411fbfe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:21:08.130517Z",
     "start_time": "2025-05-04T23:21:06.969426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Taken from https://medium.com/analytics-vidhya/topic-modeling-using-gensim-lda-in-python-48eaa2344920\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def eval_model(model, text, dic, corp):\n",
    "    # Compute Perplexity\n",
    "    perp = model.log_perplexity(corp)\n",
    "    # a measure of how good the model is. lower the better.\n",
    "    \n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=model, texts=text, dictionary=dic, coherence='c_v')\n",
    "    coherence = coherence_model_lda.get_coherence()\n",
    "    \n",
    "    return perp, coherence\n",
    "\n",
    "def plot_evals(perps, coherences, ks):\n",
    "    \n",
    "    fig = plt.figure(\"Perplexity and Coherence Analysis\", figsize=(8, 8))\n",
    "    axgrid = fig.add_gridspec(1, 2)\n",
    "    \n",
    "    ax1 = fig.add_subplot(axgrid[0, 0])\n",
    "    ax1.plot(ks, perps)\n",
    "    ax1.set_title(\"Number of topics vs Perplexity Score\")\n",
    "    ax1.set_xlabel(\"Number of Topics\")\n",
    "    ax1.set_ylabel(\"Perplexity Score\")\n",
    "    ax1.grid()\n",
    "    \n",
    "    ax2 = fig.add_subplot(axgrid[0, 1])\n",
    "    ax2.plot(ks, coherences)\n",
    "    ax2.set_title(\"Number of topics vs Coherence Score\")\n",
    "    ax2.set_xlabel(\"Number of Topics\")\n",
    "    ax2.set_ylabel(\"Coherence Score\")\n",
    "    ax2.grid()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def full_model_test_loop(text, corpus, dictionary):\n",
    "    ks = [1,2,3,4,5,6,7,8,9,10, 20, 30]\n",
    "    perps = []\n",
    "    coherences = []\n",
    "    for k in ks:\n",
    "        ldamodel = models.ldamodel.LdaModel(corpus, num_topics=k, id2word=dictionary, passes=20, random_state=RANDOM_STATE)\n",
    "        scores = eval_model(ldamodel, text.tolist(), dictionary, corpus)\n",
    "        perps.append(scores[0])\n",
    "        coherences.append(scores[1])\n",
    "    plot_evals(perps, coherences, ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a346c5d2f3e50ae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:21:08.179909Z",
     "start_time": "2025-05-04T23:21:08.172414Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Comments eval:\")\n",
    "# full_model_test_loop(preprocessed_comments, corpus_comments, dictionary_comments)\n",
    "# print(\"Post Content eval:\")\n",
    "# full_model_test_loop(preprocessed_post_content, corpus_post_content, dictionary_post_content)\n",
    "# print(\"Post Title eval:\")\n",
    "# full_model_test_loop(preprocessed_title , corpus_title, dictionary_title)\n",
    "\n",
    "# 22 minutes to run all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7495206ee602d2c",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec4df67d883cf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:27:33.774754Z",
     "start_time": "2025-05-04T23:21:08.197562Z"
    }
   },
   "outputs": [],
   "source": [
    "ldamodel_comments = models.ldamodel.LdaModel(corpus_comments, num_topics=10, id2word=dictionary_comments, passes=20, random_state=RANDOM_STATE)\n",
    "ldamodel_post_content = models.ldamodel.LdaModel(corpus_post_content, num_topics=5, id2word=dictionary_post_content, passes=20, random_state=RANDOM_STATE)\n",
    "ldamodel_title = models.ldamodel.LdaModel(corpus_title, num_topics=20, id2word=dictionary_title, passes=20, random_state=RANDOM_STATE)\n",
    "\n",
    "# 6 min 30 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0b61ae41f9b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: call eval_model to get the perplexity and coherence of the top k model and present them in table\n",
    "def evaluate_models_and_present_table(text, corpus, dictionary, ks):\n",
    "    results = []\n",
    "\n",
    "    for k in ks:\n",
    "        print(f\"Evaluating model with {k} topics...\")\n",
    "        # Train the LDA model\n",
    "        ldamodel = models.ldamodel.LdaModel(\n",
    "            corpus=corpus,\n",
    "            num_topics=k,\n",
    "            id2word=dictionary,\n",
    "            passes=20,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        # Evaluate the model\n",
    "        perplexity, coherence = eval_model(ldamodel, text, dictionary, corpus)\n",
    "        results.append({\"Topics\": k, \"Perplexity\": perplexity, \"Coherence\": coherence})\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Print the table\n",
    "    print(results_df)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Example usage\n",
    "ks = [2, 5, 10, 15, 20]  # List of topic numbers to evaluate\n",
    "results_table = evaluate_models_and_present_table(preprocessed_comments.tolist(), corpus_comments, dictionary_comments, ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5cfaa84ba6d46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:27:34.283481Z",
     "start_time": "2025-05-04T23:27:34.273881Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Comment topics:\")\n",
    "ldamodel_comments.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8308c939e5c1dda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:27:34.623457Z",
     "start_time": "2025-05-04T23:27:34.614468Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Post content topics:\")\n",
    "ldamodel_post_content.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99352b2466c1852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:27:34.975071Z",
     "start_time": "2025-05-04T23:27:34.965586Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Title topics:\")\n",
    "ldamodel_title.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38d76ec33aa551a",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adad60b440bfdb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:28:22.064441Z",
     "start_time": "2025-05-04T23:28:22.060899Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#TODO plot histogram of scores, plot distribution of compound scores\n",
    "def plot_scores(scores):\n",
    "    ax = sns.histplot(scores.melt(value_vars=[\"neg\", \"pos\", \"neu\"]), x=\"value\", hue=\"variable\",\n",
    "    multiple=\"dodge\", stat=\"percent\", common_bins=True, common_norm=True, bins=20)\n",
    "    ax.set_ylim(0, 50)\n",
    "    return ax\n",
    "\n",
    "def plot_sentiment_distribution(scores, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plot_scores(scores)\n",
    "    plt.title('Distribution of Sentiment Scores for ' + title)\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Percent')\n",
    "    plt.show()\n",
    "def plot_compound_distribution(scores, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.histplot(scores[\"compound\"], bins=20)\n",
    "    ax.set_ylim(0, 50)\n",
    "    plt.title('Distribution of Compound Sentiment Scores for ' + title)\n",
    "    plt.xlabel('Compound Score')\n",
    "    plt.ylabel('Percent')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69da25e1750478b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T01:40:19.721878Z",
     "start_time": "2025-05-05T01:40:19.704715Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def find_all_sentiments(document):\n",
    "    sentences = sent_tokenize(document)\n",
    "    document_scores = {\"pos\":0, \"neu\":0, \"neg\":0, \"compound\":0}\n",
    "    for sentence in sentences:\n",
    "        sentence_scores = sid.polarity_scores(sentence)\n",
    "        document_scores[\"compound\"] += sentence_scores[\"compound\"]\n",
    "        document_scores[\"neg\"] += sentence_scores[\"neg\"]\n",
    "        document_scores[\"neu\"] += sentence_scores[\"neu\"]\n",
    "        document_scores[\"pos\"] += sentence_scores[\"pos\"]    \n",
    "    num_sent = len(sentences)\n",
    "    document_scores[\"compound\"] /= num_sent\n",
    "    document_scores[\"neg\"] /= num_sent\n",
    "    document_scores[\"neu\"] /= num_sent\n",
    "    document_scores[\"pos\"] /= num_sent\n",
    "    return document_scores\n",
    "\n",
    "\n",
    "    \n",
    "def find_all_topic_sentiments(corp, documents, model):\n",
    "    dominant_topics = []\n",
    "    document_scores = []\n",
    "    corpdoc = zip(corp, documents) # Link each corpus \"bag\" representation with the full document\n",
    "    for bag, document in corpdoc:\n",
    "        topics = model.get_document_topics(bag)\n",
    "        dominant_topic = max(topics, key=lambda x: x[1])[0]\n",
    "        dominant_topics.append(dominant_topic)\n",
    "        document_scores.append(find_all_sentiments(document))\n",
    "        \n",
    "    document_scores_df = pd.DataFrame(document_scores) # Each set of sentiments represents a document\n",
    "    document_scores_df[\"text\"] = documents\n",
    "    document_scores_df[\"topic\"] = dominant_topics # Also add the dominant topic\n",
    "    \n",
    "    topic_sentiments = document_scores_df.groupby(\"topic\")[[\"pos\",\"neu\",\"neg\",\"compound\"]].mean()\n",
    "        \n",
    "    return topic_sentiments, document_scores_df.drop(\"topic\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332401e1cfd1b731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T01:43:43.097669Z",
     "start_time": "2025-05-05T01:40:24.334278Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_comments = clean_column(df_recent, \"self_text\")[\"self_text\"]\n",
    "comment_topic_sentiments, comment_document_sentiments = find_all_topic_sentiments(corpus_comments, clean_comments, ldamodel_comments)\n",
    "# 3 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea6f35518f4902",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T01:43:43.129228Z",
     "start_time": "2025-05-05T01:43:43.113671Z"
    }
   },
   "outputs": [],
   "source": [
    "comment_document_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sentiment distribution for all posts\n",
    "plot_sentiment_distribution(comment_document_sentiments[['neg', 'pos', 'neu']], 'All Posts')\n",
    "plot_compound_distribution(comment_document_sentiments['compound'], 'All Posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd594f6bf815270",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-05T01:44:32.995680Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "clean_column(df_recent, \"self_text\")[\"self_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811fecc89ffe11f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T01:43:43.666567Z",
     "start_time": "2025-05-05T01:43:43.645343Z"
    }
   },
   "outputs": [],
   "source": [
    "comment_topic_sentiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
