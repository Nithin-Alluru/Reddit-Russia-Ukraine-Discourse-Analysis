{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T20:39:53.399408Z",
     "start_time": "2025-05-06T20:39:53.390419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get preprocessing methods from make_network.ipynb to keep consistent.\n",
    "RANDOM_STATE = 5664\n",
    "import os\n",
    "import pandas as pd\n",
    "def load_and_clean_data(filepath):\n",
    "    \"\"\"\n",
    "    Load Reddit data and remove duplicate user-subreddit combinations.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the CSV data file\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Cleaned dataframe with unique user-subreddit combinations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(filepath):\n",
    "            raise FileNotFoundError(f\"Data file not found: {filepath}\")\n",
    "            \n",
    "        # Load the dataset\n",
    "        print(f\"Loading data from {filepath}...\")\n",
    "        df = pd.read_csv(filepath)\n",
    "        print(f\"Original data shape: {df.shape}\")\n",
    "        \n",
    "        # Remove exact duplicates\n",
    "        df_unique = df.drop_duplicates().copy()\n",
    "        \n",
    "        print(f\"Data shape after removing exact duplicates: {df_unique.shape}\")\n",
    "        \n",
    "        return df_unique\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in load_and_clean_data: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "def analyze_post_dates(df):\n",
    "    # Convert post_created_time to datetime\n",
    "    df['post_created_time'] = pd.to_datetime(df['post_created_time'])\n",
    "    \n",
    "    # Get the earliest and latest dates\n",
    "    min_date = df['post_created_time'].min()\n",
    "    max_date = df['post_created_time'].max()\n",
    "    \n",
    "    return min_date, max_date\n",
    "\n",
    "def filter_by_date(df, start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Filter dataframe to include only posts within a specific date range.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame with 'post_created_time' column\n",
    "        start_date (str, datetime, optional): Keep posts on or after this date\n",
    "        end_date (str, datetime, optional): Keep posts on or before this date\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Filtered dataframe\n",
    "    \"\"\"\n",
    "    # Make sure post_created_time is datetime\n",
    "    if not pd.api.types.is_datetime64_dtype(df['post_created_time']):\n",
    "        df['post_created_time'] = pd.to_datetime(df['post_created_time'])\n",
    "    \n",
    "    original_count = len(df)\n",
    "    \n",
    "    # Apply date filters\n",
    "    if start_date is not None:\n",
    "        if isinstance(start_date, str):\n",
    "            start_date = pd.to_datetime(start_date)\n",
    "        df = df[df['post_created_time'] >= start_date]\n",
    "    \n",
    "    if end_date is not None:\n",
    "        if isinstance(end_date, str):\n",
    "            end_date = pd.to_datetime(end_date)\n",
    "        df = df[df['post_created_time'] <= end_date]\n",
    "    \n",
    "    # Report on filtering\n",
    "    print(f\"Date filtering:\")\n",
    "    if start_date is not None:\n",
    "        print(f\"  Start date: {start_date}\")\n",
    "    if end_date is not None:\n",
    "        print(f\"  End date: {end_date}\")\n",
    "    print(f\"  Original records: {original_count}\")\n",
    "    print(f\"  Filtered records: {len(df)} ({len(df)/original_count*100:.1f}% retained)\")\n",
    "    \n",
    "    return df"
   ],
   "id": "189120c123e833e4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data",
   "id": "16770055ed9fabad"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-06T20:41:24.296243Z",
     "start_time": "2025-05-06T20:39:53.420549Z"
    }
   },
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "df_clean = load_and_clean_data(\"reddit_opinion_ru_ua.csv\")\n",
    "min_date, max_date = analyze_post_dates(df_clean)\n",
    "cutoff_date = max_date - timedelta(days=10)\n",
    "\n",
    "df_recent = filter_by_date(df_clean, start_date=cutoff_date)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from reddit_opinion_ru_ua.csv...\n",
      "Original data shape: (5168018, 24)\n",
      "Data shape after removing exact duplicates: (5168018, 24)\n",
      "Date filtering:\n",
      "  Start date: 2025-04-19 11:00:47\n",
      "  Original records: 5168018\n",
      "  Filtered records: 95660 (1.9% retained)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T20:41:26.048905Z",
     "start_time": "2025-05-06T20:41:25.939671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "todrop = [\"comment_id\", \"created_time\",\"post_id\",\"user_is_verified\",\"user_account_created_time\", \"user_awardee_karma\", \"user_awarder_karma\", \"user_comment_karma\", \"user_link_karma\", \"post_created_time\"]\n",
    "df_recent.drop(todrop, axis=1).copy()\n",
    "df_recent"
   ],
   "id": "80ce2289a8e5840c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      comment_id  score                                          self_text  \\\n",
       "0        mpn18ju      1  I'd have to agree that it's hard to shop for m...   \n",
       "1        mpn188l      1  They don't, so you don't have to worry about t...   \n",
       "2        mpn16la      1  Trump is just buying time.  He won't do shit t...   \n",
       "3        mpn14md      1  They are being randomly called up for military...   \n",
       "4        mpn141c      1  Most of your assumptions here are wrong.\\n\\nFi...   \n",
       "...          ...    ...                                                ...   \n",
       "99005    mnwrug7     44                             Zelensky’s humiliated    \n",
       "99024    mnwrjba     36                           Some people learn slowly   \n",
       "99048    mnwracf    917  So in 2025 we’ve got Russian horse logistics c...   \n",
       "99114    mnwqfyb      3  Pinged EUROPE ([subscribe](https://reddit.com/...   \n",
       "99116    mnwqfnr     29                       !ping EUROPE\\n\\nBrave woman.   \n",
       "\n",
       "                   subreddit         created_time  post_id  \\\n",
       "0                AskARussian  2025-04-29 11:08:21  1kaa04k   \n",
       "1                     europe  2025-04-29 11:08:16  1kajrb4   \n",
       "2      UkraineWarVideoReport  2025-04-29 11:07:55  1kajrn6   \n",
       "3                  worldnews  2025-04-29 11:07:29  1kaipov   \n",
       "4                  worldnews  2025-04-29 11:07:21  1kaipov   \n",
       "...                      ...                  ...      ...   \n",
       "99005    UkraineRussiaReport  2025-04-19 11:18:32  1k2tvsk   \n",
       "99024          CombatFootage  2025-04-19 11:15:48  1k2ts9o   \n",
       "99048          CombatFootage  2025-04-19 11:13:34  1k2ts9o   \n",
       "99114             neoliberal  2025-04-19 11:05:51  1k2tru1   \n",
       "99116             neoliberal  2025-04-19 11:05:47  1k2tru1   \n",
       "\n",
       "                author_name  controversiality  ups  downs  ...  \\\n",
       "0                  rsaachit                 0    1      0  ...   \n",
       "1                potatolulz                 0    1      0  ...   \n",
       "2      Many-Cartographer-45                 0    1      0  ...   \n",
       "3                     Corka                 0    1      0  ...   \n",
       "4               LeSygneNoir                 0    1      0  ...   \n",
       "...                     ...               ...  ...    ...  ...   \n",
       "99005       Cmoibenlepro123                 0   44      0  ...   \n",
       "99024      Ancient-Tax-8129                 0   36      0  ...   \n",
       "99048  Dangerous_Horse_2794                 0  917      0  ...   \n",
       "99114              groupbot                 0    3      0  ...   \n",
       "99116           BubsyFanboy                 0   29      0  ...   \n",
       "\n",
       "       user_link_karma user_comment_karma  user_total_karma  post_score  \\\n",
       "0               1462.0              810.0            2272.0           8   \n",
       "1              11179.0           594349.0          605528.0         590   \n",
       "2                  1.0             2491.0            2492.0         134   \n",
       "3                789.0           136268.0          137057.0        2185   \n",
       "4              32188.0           180480.0          212668.0        2185   \n",
       "...                ...                ...               ...         ...   \n",
       "99005            416.0             5156.0            5572.0         159   \n",
       "99024             40.0            35412.0           35452.0        4279   \n",
       "99048            539.0             1498.0            2037.0        4279   \n",
       "99114              3.0           137119.0          137122.0          98   \n",
       "99116         527180.0           794384.0         1321564.0          98   \n",
       "\n",
       "                                          post_self_text  \\\n",
       "0      hello!! I’m currently trying to come up with g...   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "99005                                                NaN   \n",
       "99024                                                NaN   \n",
       "99048                                                NaN   \n",
       "99114  **A Russian court handed down a prison sentenc...   \n",
       "99116  **A Russian court handed down a prison sentenc...   \n",
       "\n",
       "                                              post_title  post_upvote_ratio  \\\n",
       "0               Gifts for Russian man - from an American               0.78   \n",
       "1      Zelensky dismisses Putin’s declaration of a 72...               0.98   \n",
       "2      The real Putin is now clear to Trump - and his...               0.95   \n",
       "3      Russia has lost over 950,000 soldiers since Fe...               0.97   \n",
       "4      Russia has lost over 950,000 soldiers since Fe...               0.97   \n",
       "...                                                  ...                ...   \n",
       "99005  RU POV: The Russian Army Iiberated Oleshnya af...               0.89   \n",
       "99024  The most unusual piece of equipment used by th...               0.99   \n",
       "99048  The most unusual piece of equipment used by th...               0.99   \n",
       "99114  Anti-war graffiti and poetry costs Russian act...               1.00   \n",
       "99116  Anti-war graffiti and poetry costs Russian act...               1.00   \n",
       "\n",
       "       post_thumbs_ups post_total_awards_received   post_created_time  \n",
       "0                    8                          0 2025-04-28 23:37:58  \n",
       "1                  590                          0 2025-04-29 09:27:03  \n",
       "2                  134                          0 2025-04-29 09:27:45  \n",
       "3                 2185                          0 2025-04-29 08:07:53  \n",
       "4                 2185                          0 2025-04-29 08:07:53  \n",
       "...                ...                        ...                 ...  \n",
       "99005              159                          0 2025-04-19 11:11:43  \n",
       "99024             4279                          0 2025-04-19 11:05:18  \n",
       "99048             4279                          0 2025-04-19 11:05:18  \n",
       "99114               98                          0 2025-04-19 11:04:32  \n",
       "99116               98                          0 2025-04-19 11:04:32  \n",
       "\n",
       "[95660 rows x 24 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "      <th>post_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>...</th>\n",
       "      <th>user_link_karma</th>\n",
       "      <th>user_comment_karma</th>\n",
       "      <th>user_total_karma</th>\n",
       "      <th>post_score</th>\n",
       "      <th>post_self_text</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_upvote_ratio</th>\n",
       "      <th>post_thumbs_ups</th>\n",
       "      <th>post_total_awards_received</th>\n",
       "      <th>post_created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mpn18ju</td>\n",
       "      <td>1</td>\n",
       "      <td>I'd have to agree that it's hard to shop for m...</td>\n",
       "      <td>AskARussian</td>\n",
       "      <td>2025-04-29 11:08:21</td>\n",
       "      <td>1kaa04k</td>\n",
       "      <td>rsaachit</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>8</td>\n",
       "      <td>hello!! I’m currently trying to come up with g...</td>\n",
       "      <td>Gifts for Russian man - from an American</td>\n",
       "      <td>0.78</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-28 23:37:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mpn188l</td>\n",
       "      <td>1</td>\n",
       "      <td>They don't, so you don't have to worry about t...</td>\n",
       "      <td>europe</td>\n",
       "      <td>2025-04-29 11:08:16</td>\n",
       "      <td>1kajrb4</td>\n",
       "      <td>potatolulz</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11179.0</td>\n",
       "      <td>594349.0</td>\n",
       "      <td>605528.0</td>\n",
       "      <td>590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zelensky dismisses Putin’s declaration of a 72...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>590</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29 09:27:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mpn16la</td>\n",
       "      <td>1</td>\n",
       "      <td>Trump is just buying time.  He won't do shit t...</td>\n",
       "      <td>UkraineWarVideoReport</td>\n",
       "      <td>2025-04-29 11:07:55</td>\n",
       "      <td>1kajrn6</td>\n",
       "      <td>Many-Cartographer-45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The real Putin is now clear to Trump - and his...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29 09:27:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mpn14md</td>\n",
       "      <td>1</td>\n",
       "      <td>They are being randomly called up for military...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2025-04-29 11:07:29</td>\n",
       "      <td>1kaipov</td>\n",
       "      <td>Corka</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>789.0</td>\n",
       "      <td>136268.0</td>\n",
       "      <td>137057.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russia has lost over 950,000 soldiers since Fe...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2185</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29 08:07:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mpn141c</td>\n",
       "      <td>1</td>\n",
       "      <td>Most of your assumptions here are wrong.\\n\\nFi...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2025-04-29 11:07:21</td>\n",
       "      <td>1kaipov</td>\n",
       "      <td>LeSygneNoir</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32188.0</td>\n",
       "      <td>180480.0</td>\n",
       "      <td>212668.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russia has lost over 950,000 soldiers since Fe...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2185</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29 08:07:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99005</th>\n",
       "      <td>mnwrug7</td>\n",
       "      <td>44</td>\n",
       "      <td>Zelensky’s humiliated</td>\n",
       "      <td>UkraineRussiaReport</td>\n",
       "      <td>2025-04-19 11:18:32</td>\n",
       "      <td>1k2tvsk</td>\n",
       "      <td>Cmoibenlepro123</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>416.0</td>\n",
       "      <td>5156.0</td>\n",
       "      <td>5572.0</td>\n",
       "      <td>159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RU POV: The Russian Army Iiberated Oleshnya af...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-19 11:11:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99024</th>\n",
       "      <td>mnwrjba</td>\n",
       "      <td>36</td>\n",
       "      <td>Some people learn slowly</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2025-04-19 11:15:48</td>\n",
       "      <td>1k2ts9o</td>\n",
       "      <td>Ancient-Tax-8129</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35412.0</td>\n",
       "      <td>35452.0</td>\n",
       "      <td>4279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The most unusual piece of equipment used by th...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4279</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-19 11:05:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99048</th>\n",
       "      <td>mnwracf</td>\n",
       "      <td>917</td>\n",
       "      <td>So in 2025 we’ve got Russian horse logistics c...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2025-04-19 11:13:34</td>\n",
       "      <td>1k2ts9o</td>\n",
       "      <td>Dangerous_Horse_2794</td>\n",
       "      <td>0</td>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>539.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>2037.0</td>\n",
       "      <td>4279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The most unusual piece of equipment used by th...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4279</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-19 11:05:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99114</th>\n",
       "      <td>mnwqfyb</td>\n",
       "      <td>3</td>\n",
       "      <td>Pinged EUROPE ([subscribe](https://reddit.com/...</td>\n",
       "      <td>neoliberal</td>\n",
       "      <td>2025-04-19 11:05:51</td>\n",
       "      <td>1k2tru1</td>\n",
       "      <td>groupbot</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>137119.0</td>\n",
       "      <td>137122.0</td>\n",
       "      <td>98</td>\n",
       "      <td>**A Russian court handed down a prison sentenc...</td>\n",
       "      <td>Anti-war graffiti and poetry costs Russian act...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-19 11:04:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99116</th>\n",
       "      <td>mnwqfnr</td>\n",
       "      <td>29</td>\n",
       "      <td>!ping EUROPE\\n\\nBrave woman.</td>\n",
       "      <td>neoliberal</td>\n",
       "      <td>2025-04-19 11:05:47</td>\n",
       "      <td>1k2tru1</td>\n",
       "      <td>BubsyFanboy</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>527180.0</td>\n",
       "      <td>794384.0</td>\n",
       "      <td>1321564.0</td>\n",
       "      <td>98</td>\n",
       "      <td>**A Russian court handed down a prison sentenc...</td>\n",
       "      <td>Anti-war graffiti and poetry costs Russian act...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-19 11:04:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95660 rows × 24 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T20:43:41.610856Z",
     "start_time": "2025-05-06T20:43:41.572138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get basic information\n",
    "print(\"Number of posts:\", len(df_recent))\n",
    "print(\"All subreddits:\")\n",
    "pd.DataFrame(df_recent.subreddit.explode().unique())"
   ],
   "id": "42ce1e145d402330",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts: 95660\n",
      "All subreddits:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                        0\n",
       "0             AskARussian\n",
       "1                  europe\n",
       "2   UkraineWarVideoReport\n",
       "3               worldnews\n",
       "4     UkraineRussiaReport\n",
       "5              conspiracy\n",
       "6                 ukraine\n",
       "7      ANormalDayInRussia\n",
       "8       UkrainianConflict\n",
       "9      russiawarinukraine\n",
       "10     NonCredibleDefense\n",
       "11      UkraineWarReports\n",
       "12  UkraineInvasionVideos\n",
       "13           MilitaryPorn\n",
       "14          CombatFootage\n",
       "15              AskReddit\n",
       "16   RussiaUkraineWar2022\n",
       "17                   news\n",
       "18           WayOfTheBern\n",
       "19               politics\n",
       "20             EndlessWar\n",
       "21        FreedomofRussia\n",
       "22        UkraineConflict\n",
       "23         LoveForUkraine\n",
       "24               Military\n",
       "25         UkraineWarRoom\n",
       "26             neoliberal\n",
       "27           Conservative\n",
       "28   volunteersForUkraine\n",
       "29            geopolitics\n",
       "30                 france\n",
       "31           RussiaDenies\n",
       "32                ukraina\n",
       "33            UkrainePics"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskARussian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UkraineWarVideoReport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UkraineRussiaReport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>conspiracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ANormalDayInRussia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UkrainianConflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>russiawarinukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NonCredibleDefense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UkraineWarReports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UkraineInvasionVideos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MilitaryPorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CombatFootage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RussiaUkraineWar2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WayOfTheBern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EndlessWar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FreedomofRussia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UkraineConflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LoveForUkraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>UkraineWarRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>neoliberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>volunteersForUkraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>geopolitics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RussiaDenies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ukraina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>UkrainePics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set up for topic modeling and sentiment analysis for comments, posts, and post titles",
   "id": "a3abd9af5e25d4ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T20:43:48.000628Z",
     "start_time": "2025-05-06T20:43:44.507995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt_tab\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "def preprocess_one_doc(text: str, lower: bool, punct: bool, stop: bool, stem: bool):\n",
    "    puncts = set(string.punctuation)\n",
    "    puncts.add(\"...\") # punct does not contain ellipses\n",
    "    puncts.add(\"…\")\n",
    "    puncts.add(\"===\")\n",
    "    puncts.add(\"—\")\n",
    "    puncts.add(\"–\")\n",
    "    puncts.add(\"“\")\n",
    "    puncts.add(\"”\")\n",
    "    puncts.add(\"’\")\n",
    "    puncts.add(\"‘\")\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    # stops.add(\"\")\n",
    "    \n",
    "    \n",
    "    # Lowercase the words depending on sentiment or topic modeling\n",
    "    if lower:\n",
    "        step0 = text.lower()\n",
    "    else:\n",
    "        step0 = text\n",
    "    step1 = word_tokenize(step0)\n",
    "    \n",
    "    \n",
    "    if punct:\n",
    "        step2 = \"\".join([ch for ch in \" \".join(step1) if ch not in puncts]).split()\n",
    "    else:\n",
    "        step2 = step1\n",
    "        \n",
    "        \n",
    "    \n",
    "    if stop:\n",
    "        # Remove stopwords\n",
    "        step3 = [token for token in step2\n",
    "                    if token not in stops # drop stopwords\n",
    "                    # and len(token) > 2 # drop words of insignificant length\n",
    "                    and (not token.startswith(\"http\"))] # drop links\n",
    "    else:\n",
    "        step3 = step2\n",
    "        \n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        step4 = [stemmer.stem(i) for i in step3]\n",
    "    else:\n",
    "        step4 = step3\n",
    "        \n",
    "    return step4\n",
    "\n",
    "from gensim import corpora, models\n",
    "\n",
    "def make_dictionary(alltexts):\n",
    "    d = corpora.Dictionary(alltexts)\n",
    "    d.filter_extremes(no_below=5, no_above=0.3) # Keep words that are in more than 5 documents, but not in more than a third of all documents\n",
    "    d.compactify()\n",
    "    return d\n",
    "\n",
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = RANDOM_STATE\n",
    "\n",
    "def filter_english(text):\n",
    "    try:\n",
    "        return detect(text) == \"en\"\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def clean_column(df, text_column_name):\n",
    "    # Drop all missing values\n",
    "    dfc = df.copy()\n",
    "    dfc.dropna(subset=[text_column_name], inplace=True)\n",
    "    \n",
    "    # Filter non-english text\n",
    "    is_english = dfc[text_column_name].apply(filter_english)\n",
    "    dfc = dfc[is_english]\n",
    "    return dfc\n",
    "\n",
    "def make_all_components(df, text_column_name):\n",
    "    dfc = clean_column(df, text_column_name)\n",
    "    \n",
    "    # Create with standard preprocessing\n",
    "    preprocessed = dfc[text_column_name].apply(lambda x: preprocess_one_doc(x, lower=True, stop=True, punct=True, stem=True)) # Preprocess all docs\n",
    "    dictionary = make_dictionary(preprocessed.tolist()) # Use list of lists of strings\n",
    "    corpus = [dictionary.doc2bow(text) for text in preprocessed.tolist()] # bag of words representation of documents\n",
    "    return preprocessed, dictionary, corpus"
   ],
   "id": "e3ce9e99aa141aca",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-06T20:43:48.005635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create with standard preprocessing\n",
    "preprocessed_comments, dictionary_comments, corpus_comments = make_all_components(df_recent, \"self_text\")\n",
    "preprocessed_post_content, dictionary_post_content, corpus_post_content = make_all_components(df_recent, \"post_self_text\")\n",
    "preprocessed_title, dictionary_title, corpus_title = make_all_components(df_recent, \"post_title\")"
   ],
   "id": "c55303aacf345955",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T20:44:40.472864Z",
     "start_time": "2025-05-04T23:21:06.487963Z"
    }
   },
   "cell_type": "code",
   "source": "preprocessed_comments",
   "id": "e8147f7807cbddb5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [agre, hard, shop, men, unless, nich, hobbi, l...\n",
       "1                                          [nt, nt, worri]\n",
       "2        [trump, buy, time, wo, nt, shit, help, defeat,...\n",
       "3        [randomli, call, militari, servic, period, one...\n",
       "4        [assumpt, wrong, first, consid, overal, size, ...\n",
       "                               ...                        \n",
       "98869                                [someon, play, metro]\n",
       "98884                         [time, europ, take, respons]\n",
       "98991    [whoever, mix, music, video, clearli, miss, go...\n",
       "99003                     [russia, choochoochoos, violenc]\n",
       "99048    [2025, got, russian, hors, logist, convoy, lar...\n",
       "Name: self_text, Length: 38171, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate to find best number of topics",
   "id": "fcf9da0fb2263625"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:21:08.130517Z",
     "start_time": "2025-05-04T23:21:06.969426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Taken from https://medium.com/analytics-vidhya/topic-modeling-using-gensim-lda-in-python-48eaa2344920\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def eval_model(model, text, dic, corp):\n",
    "    # Compute Perplexity\n",
    "    perp = model.log_perplexity(corp)\n",
    "    # a measure of how good the model is. lower the better.\n",
    "    \n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=model, texts=text, dictionary=dic, coherence='c_v')\n",
    "    coherence = coherence_model_lda.get_coherence()\n",
    "    \n",
    "    return perp, coherence\n",
    "\n",
    "def plot_evals(perps, coherences, ks):\n",
    "    \n",
    "    fig = plt.figure(\"Perplexity and Coherence Analysis\", figsize=(8, 8))\n",
    "    axgrid = fig.add_gridspec(1, 2)\n",
    "    \n",
    "    ax1 = fig.add_subplot(axgrid[0, 0])\n",
    "    ax1.plot(ks, perps)\n",
    "    ax1.set_title(\"Number of topics vs Perplexity Score\")\n",
    "    ax1.set_xlabel(\"Number of Topics\")\n",
    "    ax1.set_ylabel(\"Perplexity Score\")\n",
    "    ax1.grid()\n",
    "    \n",
    "    ax2 = fig.add_subplot(axgrid[0, 1])\n",
    "    ax2.plot(ks, coherences)\n",
    "    ax2.set_title(\"Number of topics vs Coherence Score\")\n",
    "    ax2.set_xlabel(\"Number of Topics\")\n",
    "    ax2.set_ylabel(\"Coherence Score\")\n",
    "    ax2.grid()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def full_model_test_loop(text, corpus, dictionary):\n",
    "    ks = [1,2,3,4,5,6,7,8,9,10, 20, 30]\n",
    "    perps = []\n",
    "    coherences = []\n",
    "    for k in ks:\n",
    "        ldamodel = models.ldamodel.LdaModel(corpus, num_topics=k, id2word=dictionary, passes=20, random_state=RANDOM_STATE)\n",
    "        scores = eval_model(ldamodel, text.tolist(), dictionary, corpus)\n",
    "        perps.append(scores[0])\n",
    "        coherences.append(scores[1])\n",
    "    plot_evals(perps, coherences, ks)"
   ],
   "id": "ffc8ece3411fbfe4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:21:08.179909Z",
     "start_time": "2025-05-04T23:21:08.172414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(\"Comments eval:\")\n",
    "# full_model_test_loop(preprocessed_comments, corpus_comments, dictionary_comments)\n",
    "# print(\"Post Content eval:\")\n",
    "# full_model_test_loop(preprocessed_post_content, corpus_post_content, dictionary_post_content)\n",
    "# print(\"Post Title eval:\")\n",
    "# full_model_test_loop(preprocessed_title , corpus_title, dictionary_title)\n",
    "\n",
    "# 22 minutes to run all"
   ],
   "id": "a346c5d2f3e50ae0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Topic Modeling",
   "id": "d7495206ee602d2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:27:33.774754Z",
     "start_time": "2025-05-04T23:21:08.197562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ldamodel_comments = models.ldamodel.LdaModel(corpus_comments, num_topics=10, id2word=dictionary_comments, passes=20, random_state=RANDOM_STATE)\n",
    "ldamodel_post_content = models.ldamodel.LdaModel(corpus_post_content, num_topics=5, id2word=dictionary_post_content, passes=20, random_state=RANDOM_STATE)\n",
    "ldamodel_title = models.ldamodel.LdaModel(corpus_title, num_topics=20, id2word=dictionary_title, passes=20, random_state=RANDOM_STATE)\n",
    "\n",
    "# 6 min 30 sec"
   ],
   "id": "6dec4df67d883cf8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO: call eval_model to get the perplexity and coherence of the top k model and present them in table",
   "id": "b9d0b61ae41f9b30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:27:34.283481Z",
     "start_time": "2025-05-04T23:27:34.273881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Comment topics:\")\n",
    "ldamodel_comments.show_topics()"
   ],
   "id": "f0e5cfaa84ba6d46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment topics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.034*\"war\" + 0.033*\"day\" + 0.032*\"said\" + 0.029*\"gt\" + 0.021*\"end\" + 0.020*\"bomb\" + 0.019*\"one\" + 0.019*\"na\" + 0.014*\"gon\" + 0.014*\"moscow\"'),\n",
       " (1,\n",
       "  '0.064*\"ukrain\" + 0.050*\"russia\" + 0.020*\"nt\" + 0.020*\"war\" + 0.018*\"want\" + 0.018*\"would\" + 0.015*\"peac\" + 0.014*\"us\" + 0.012*\"putin\" + 0.012*\"give\"'),\n",
       " (2,\n",
       "  '0.085*\"fuck\" + 0.033*\"easter\" + 0.031*\"yeah\" + 0.026*\"amp\" + 0.020*\"god\" + 0.017*\"oh\" + 0.014*\"hour\" + 0.013*\"hear\" + 0.013*\"church\" + 0.013*\"pleas\"'),\n",
       " (3,\n",
       "  '0.031*\"kill\" + 0.026*\"thank\" + 0.018*\"orang\" + 0.017*\"shit\" + 0.014*\"peopl\" + 0.013*\"children\" + 0.011*\"say\" + 0.011*\"show\" + 0.010*\"red\" + 0.010*\"human\"'),\n",
       " (4,\n",
       "  '0.079*\"trump\" + 0.049*\"putin\" + 0.028*\"like\" + 0.020*\"look\" + 0.012*\"make\" + 0.010*\"presid\" + 0.010*\"zelenski\" + 0.009*\"play\" + 0.008*\"get\" + 0.008*\"biden\"'),\n",
       " (5,\n",
       "  '0.054*\"nt\" + 0.025*\"peopl\" + 0.017*\"say\" + 0.015*\"know\" + 0.015*\"think\" + 0.012*\"like\" + 0.011*\"would\" + 0.010*\"believ\" + 0.010*\"want\" + 0.010*\"american\"'),\n",
       " (6,\n",
       "  '0.027*\"year\" + 0.023*\"see\" + 0.020*\"time\" + 0.018*\"got\" + 0.015*\"love\" + 0.015*\"one\" + 0.014*\"hope\" + 0.014*\"get\" + 0.014*\"go\" + 0.012*\"ye\"'),\n",
       " (7,\n",
       "  '0.044*\"russian\" + 0.020*\"ukrainian\" + 0.020*\"drone\" + 0.019*\"use\" + 0.013*\"missil\" + 0.010*\"target\" + 0.009*\"attack\" + 0.008*\"train\" + 0.008*\"air\" + 0.007*\"militari\"'),\n",
       " (8,\n",
       "  '0.021*\"like\" + 0.011*\"peopl\" + 0.010*\"russian\" + 0.009*\"lot\" + 0.009*\"much\" + 0.009*\"also\" + 0.008*\"would\" + 0.008*\"use\" + 0.007*\"thing\" + 0.007*\"good\"'),\n",
       " (9,\n",
       "  '0.027*\"us\" + 0.021*\"russia\" + 0.018*\"countri\" + 0.012*\"state\" + 0.009*\"eu\" + 0.008*\"world\" + 0.008*\"war\" + 0.008*\"power\" + 0.008*\"china\" + 0.007*\"russian\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:27:34.623457Z",
     "start_time": "2025-05-04T23:27:34.614468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Post content topics:\")\n",
    "ldamodel_post_content.show_topics()"
   ],
   "id": "f8308c939e5c1dda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post content topics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.017*\"war\" + 0.012*\"trump\" + 0.012*\"video\" + 0.011*\"sourc\" + 0.010*\"ukrain\" + 0.010*\"us\" + 0.009*\"inform\" + 0.008*\"realiti\" + 0.008*\"document\" + 0.008*\"educ\"'),\n",
       " (1,\n",
       "  '0.012*\"would\" + 0.011*\"ukrain\" + 0.011*\"want\" + 0.008*\"like\" + 0.008*\"amp\" + 0.007*\"live\" + 0.007*\"peopl\" + 0.007*\"get\" + 0.007*\"ukrainian\" + 0.006*\"realli\"'),\n",
       " (2,\n",
       "  '0.011*\"would\" + 0.009*\"like\" + 0.009*\"nt\" + 0.009*\"lawn\" + 0.007*\"name\" + 0.006*\"peopl\" + 0.006*\"think\" + 0.005*\"said\" + 0.005*\"elect\" + 0.005*\"time\"'),\n",
       " (3,\n",
       "  '0.018*\"soldier\" + 0.010*\"ukrainian\" + 0.010*\"ukrain\" + 0.008*\"colombian\" + 0.008*\"one\" + 0.006*\"forc\" + 0.006*\"unit\" + 0.006*\"said\" + 0.006*\"gt\" + 0.005*\"drone\"'),\n",
       " (4,\n",
       "  '0.013*\"banksi\" + 0.011*\"nt\" + 0.008*\"artist\" + 0.007*\"would\" + 0.007*\"administr\" + 0.006*\"rob\" + 0.006*\"trump\" + 0.006*\"never\" + 0.005*\"work\" + 0.005*\"time\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:27:34.975071Z",
     "start_time": "2025-05-04T23:27:34.965586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Title topics:\")\n",
    "ldamodel_title.show_topics()"
   ],
   "id": "f99352b2466c1852",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title topics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  '0.133*\"russia\" + 0.082*\"hour\" + 0.078*\"fight\" + 0.065*\"offic\" + 0.062*\"time\" + 0.050*\"violat\" + 0.043*\"first\" + 0.042*\"offici\" + 0.034*\"admit\" + 0.032*\"troop\"'),\n",
       " (4,\n",
       "  '0.225*\"truce\" + 0.190*\"ceasefir\" + 0.078*\"ua\" + 0.074*\"sinc\" + 0.074*\"pov\" + 0.047*\"may\" + 0.041*\"announc\" + 0.026*\"territori\" + 0.022*\"includ\" + 0.018*\"order\"'),\n",
       " (19,\n",
       "  '0.119*\"claim\" + 0.078*\"air\" + 0.060*\"place\" + 0.058*\"back\" + 0.056*\"play\" + 0.048*\"within\" + 0.048*\"gener\" + 0.046*\"jet\" + 0.043*\"await\" + 0.040*\"true\"'),\n",
       " (15,\n",
       "  '0.105*\"attack\" + 0.093*\"moscow\" + 0.080*\"along\" + 0.072*\"join\" + 0.065*\"show\" + 0.049*\"pope\" + 0.049*\"nsfw\" + 0.046*\"negoti\" + 0.039*\"may\" + 0.034*\"9\"'),\n",
       " (11,\n",
       "  '0.099*\"trump\" + 0.081*\"peopl\" + 0.077*\"russia\" + 0.076*\"plan\" + 0.074*\"propos\" + 0.051*\"away\" + 0.046*\"reject\" + 0.045*\"one\" + 0.044*\"launch\" + 0.043*\"warn\"'),\n",
       " (18,\n",
       "  '0.245*\"putin\" + 0.128*\"war\" + 0.126*\"trump\" + 0.116*\"declar\" + 0.061*\"end\" + 0.048*\"call\" + 0.045*\"start\" + 0.033*\"donald\" + 0.032*\"say\" + 0.026*\"deal\"'),\n",
       " (9,\n",
       "  '0.080*\"right\" + 0.078*\"explos\" + 0.060*\"promis\" + 0.059*\"regim\" + 0.050*\"walk\" + 0.044*\"around\" + 0.043*\"car\" + 0.038*\"train\" + 0.027*\"chief\" + 0.027*\"us\"'),\n",
       " (17,\n",
       "  '0.105*\"russia\" + 0.087*\"rubio\" + 0.077*\"new\" + 0.071*\"fire\" + 0.054*\"think\" + 0.047*\"war\" + 0.041*\"would\" + 0.040*\"weapon\" + 0.039*\"sanction\" + 0.038*\"top\"'),\n",
       " (10,\n",
       "  '0.121*\"line\" + 0.095*\"soldier\" + 0.066*\"human\" + 0.065*\"armor\" + 0.063*\"hit\" + 0.042*\"injur\" + 0.040*\"insid\" + 0.036*\"near\" + 0.031*\"mine\" + 0.031*\"flag\"'),\n",
       " (12,\n",
       "  '0.379*\"‘\" + 0.122*\"stop\" + 0.085*\"putin\" + 0.051*\"tell\" + 0.039*\"latest\" + 0.034*\"integr\" + 0.031*\"famili\" + 0.031*\"polit\" + 0.018*\"european\" + 0.018*\"updat\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sentiment Analysis",
   "id": "b38d76ec33aa551a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:28:22.064441Z",
     "start_time": "2025-05-04T23:28:22.060899Z"
    }
   },
   "cell_type": "code",
   "source": "#TODO plot histogram of scores, plot distribution of compound scores",
   "id": "2adad60b440bfdb7",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T01:40:19.721878Z",
     "start_time": "2025-05-05T01:40:19.704715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def find_all_sentiments(document):\n",
    "    sentences = sent_tokenize(document)\n",
    "    document_scores = {\"pos\":0, \"neu\":0, \"neg\":0, \"compound\":0}\n",
    "    for sentence in sentences:\n",
    "        sentence_scores = sid.polarity_scores(sentence)\n",
    "        document_scores[\"compound\"] += sentence_scores[\"compound\"]\n",
    "        document_scores[\"neg\"] += sentence_scores[\"neg\"]\n",
    "        document_scores[\"neu\"] += sentence_scores[\"neu\"]\n",
    "        document_scores[\"pos\"] += sentence_scores[\"pos\"]    \n",
    "    num_sent = len(sentences)\n",
    "    document_scores[\"compound\"] /= num_sent\n",
    "    document_scores[\"neg\"] /= num_sent\n",
    "    document_scores[\"neu\"] /= num_sent\n",
    "    document_scores[\"pos\"] /= num_sent\n",
    "    return document_scores\n",
    "\n",
    "\n",
    "    \n",
    "def find_all_topic_sentiments(corp, documents, model):\n",
    "    dominant_topics = []\n",
    "    document_scores = []\n",
    "    corpdoc = zip(corp, documents) # Link each corpus \"bag\" representation with the full document\n",
    "    for bag, document in corpdoc:\n",
    "        topics = model.get_document_topics(bag)\n",
    "        dominant_topic = max(topics, key=lambda x: x[1])[0]\n",
    "        dominant_topics.append(dominant_topic)\n",
    "        document_scores.append(find_all_sentiments(document))\n",
    "        \n",
    "    document_scores_df = pd.DataFrame(document_scores) # Each set of sentiments represents a document\n",
    "    document_scores_df[\"text\"] = documents\n",
    "    document_scores_df[\"topic\"] = dominant_topics # Also add the dominant topic\n",
    "    \n",
    "    topic_sentiments = document_scores_df.groupby(\"topic\")[[\"pos\",\"neu\",\"neg\",\"compound\"]].mean()\n",
    "        \n",
    "    return topic_sentiments, document_scores_df.drop(\"topic\", axis=1)"
   ],
   "id": "f69da25e1750478b",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#TODO Index alignment to ensure df text and scores are aligned",
   "id": "963aa925971688a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T01:43:43.097669Z",
     "start_time": "2025-05-05T01:40:24.334278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clean_comments = clean_column(df_recent, \"self_text\")[\"self_text\"]\n",
    "comment_topic_sentiments, comment_document_sentiments = find_all_topic_sentiments(corpus_comments, clean_comments, ldamodel_comments)\n",
    "# 3 minutes"
   ],
   "id": "332401e1cfd1b731",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T01:43:43.129228Z",
     "start_time": "2025-05-05T01:43:43.113671Z"
    }
   },
   "cell_type": "code",
   "source": "comment_document_sentiments",
   "id": "cfea6f35518f4902",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          pos       neu       neg  compound  \\\n",
       "0      0.2140  0.726000  0.060000  0.557400   \n",
       "1      0.4170  0.583000  0.000000  0.753500   \n",
       "2      0.2660  0.660667  0.073333  0.249300   \n",
       "3      0.0000  0.962750  0.037250 -0.096625   \n",
       "4      0.0528  0.835800  0.111350 -0.139580   \n",
       "...       ...       ...       ...       ...   \n",
       "38166  0.3100  0.690000  0.000000  0.202300   \n",
       "38167  0.0000  1.000000  0.000000  0.000000   \n",
       "38168  0.1750  0.755000  0.070000  0.255300   \n",
       "38169  0.0000  0.328000  0.672000 -0.624900   \n",
       "38170  0.0895  0.795000  0.115500 -0.142450   \n",
       "\n",
       "                                                    text  \n",
       "0      I'd have to agree that it's hard to shop for m...  \n",
       "1      They don't, so you don't have to worry about t...  \n",
       "2      Trump is just buying time.  He won't do shit t...  \n",
       "3      They are being randomly called up for military...  \n",
       "4      Most of your assumptions here are wrong.\\n\\nFi...  \n",
       "...                                                  ...  \n",
       "38166                                                NaN  \n",
       "38167                                                NaN  \n",
       "38168                                                NaN  \n",
       "38169                                                NaN  \n",
       "38170                                                NaN  \n",
       "\n",
       "[38171 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "      <th>neg</th>\n",
       "      <th>compound</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.726000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.557400</td>\n",
       "      <td>I'd have to agree that it's hard to shop for m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4170</td>\n",
       "      <td>0.583000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.753500</td>\n",
       "      <td>They don't, so you don't have to worry about t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2660</td>\n",
       "      <td>0.660667</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.249300</td>\n",
       "      <td>Trump is just buying time.  He won't do shit t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.962750</td>\n",
       "      <td>0.037250</td>\n",
       "      <td>-0.096625</td>\n",
       "      <td>They are being randomly called up for military...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.835800</td>\n",
       "      <td>0.111350</td>\n",
       "      <td>-0.139580</td>\n",
       "      <td>Most of your assumptions here are wrong.\\n\\nFi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38166</th>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38167</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38168</th>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38169</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>-0.624900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38170</th>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.115500</td>\n",
       "      <td>-0.142450</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38171 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-05T01:44:32.995680Z"
    }
   },
   "cell_type": "code",
   "source": "clean_column(df_recent, \"self_text\")[\"self_text\"]",
   "id": "2bd594f6bf815270",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T01:43:43.666567Z",
     "start_time": "2025-05-05T01:43:43.645343Z"
    }
   },
   "cell_type": "code",
   "source": "comment_topic_sentiments",
   "id": "811fecc89ffe11f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            pos       neu       neg  compound\n",
       "topic                                        \n",
       "0      0.066210  0.814469  0.106611 -0.066809\n",
       "1      0.109539  0.766219  0.120293 -0.036291\n",
       "2      0.140546  0.677626  0.169508 -0.039746\n",
       "3      0.155080  0.668022  0.161753 -0.053668\n",
       "4      0.120145  0.768581  0.106382  0.014652\n",
       "5      0.110581  0.764752  0.119601 -0.022583\n",
       "6      0.145910  0.741989  0.103407  0.036854\n",
       "7      0.087981  0.805794  0.100890 -0.046051\n",
       "8      0.109032  0.802655  0.085213  0.030286\n",
       "9      0.091021  0.805793  0.099886 -0.029056"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "      <th>neg</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066210</td>\n",
       "      <td>0.814469</td>\n",
       "      <td>0.106611</td>\n",
       "      <td>-0.066809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.109539</td>\n",
       "      <td>0.766219</td>\n",
       "      <td>0.120293</td>\n",
       "      <td>-0.036291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.140546</td>\n",
       "      <td>0.677626</td>\n",
       "      <td>0.169508</td>\n",
       "      <td>-0.039746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.155080</td>\n",
       "      <td>0.668022</td>\n",
       "      <td>0.161753</td>\n",
       "      <td>-0.053668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120145</td>\n",
       "      <td>0.768581</td>\n",
       "      <td>0.106382</td>\n",
       "      <td>0.014652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.110581</td>\n",
       "      <td>0.764752</td>\n",
       "      <td>0.119601</td>\n",
       "      <td>-0.022583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.145910</td>\n",
       "      <td>0.741989</td>\n",
       "      <td>0.103407</td>\n",
       "      <td>0.036854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.087981</td>\n",
       "      <td>0.805794</td>\n",
       "      <td>0.100890</td>\n",
       "      <td>-0.046051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.109032</td>\n",
       "      <td>0.802655</td>\n",
       "      <td>0.085213</td>\n",
       "      <td>0.030286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.091021</td>\n",
       "      <td>0.805793</td>\n",
       "      <td>0.099886</td>\n",
       "      <td>-0.029056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
