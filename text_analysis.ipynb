{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:11:45.148332Z",
     "start_time": "2025-05-04T23:11:44.106756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get preprocessing methods from make_network.ipynb to keep consistent.\n",
    "RANDOM_STATE = 5664\n",
    "import os\n",
    "import pandas as pd\n",
    "def load_and_clean_data(filepath):\n",
    "    \"\"\"\n",
    "    Load Reddit data and remove duplicate user-subreddit combinations.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the CSV data file\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Cleaned dataframe with unique user-subreddit combinations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(filepath):\n",
    "            raise FileNotFoundError(f\"Data file not found: {filepath}\")\n",
    "            \n",
    "        # Load the dataset\n",
    "        print(f\"Loading data from {filepath}...\")\n",
    "        df = pd.read_csv(filepath)\n",
    "        print(f\"Original data shape: {df.shape}\")\n",
    "        \n",
    "        # Remove duplicate user-subreddit combinations\n",
    "        df_unique = df.drop_duplicates(subset=['author_name', 'subreddit']).copy()\n",
    "        \n",
    "        print(f\"Data shape after cleaning: {df_unique.shape}\")\n",
    "        \n",
    "        return df_unique\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in load_and_clean_data: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "def analyze_post_dates(df):\n",
    "    # Convert post_created_time to datetime\n",
    "    df['post_created_time'] = pd.to_datetime(df['post_created_time'])\n",
    "    \n",
    "    # Get the earliest and latest dates\n",
    "    min_date = df['post_created_time'].min()\n",
    "    max_date = df['post_created_time'].max()\n",
    "    \n",
    "    return min_date, max_date\n",
    "\n",
    "def filter_by_date(df, start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Filter dataframe to include only posts within a specific date range.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame with 'post_created_time' column\n",
    "        start_date (str, datetime, optional): Keep posts on or after this date\n",
    "        end_date (str, datetime, optional): Keep posts on or before this date\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Filtered dataframe\n",
    "    \"\"\"\n",
    "    # Make sure post_created_time is datetime\n",
    "    if not pd.api.types.is_datetime64_dtype(df['post_created_time']):\n",
    "        df['post_created_time'] = pd.to_datetime(df['post_created_time'])\n",
    "    \n",
    "    original_count = len(df)\n",
    "    \n",
    "    # Apply date filters\n",
    "    if start_date is not None:\n",
    "        if isinstance(start_date, str):\n",
    "            start_date = pd.to_datetime(start_date)\n",
    "        df = df[df['post_created_time'] >= start_date]\n",
    "    \n",
    "    if end_date is not None:\n",
    "        if isinstance(end_date, str):\n",
    "            end_date = pd.to_datetime(end_date)\n",
    "        df = df[df['post_created_time'] <= end_date]\n",
    "    \n",
    "    # Report on filtering\n",
    "    print(f\"Date filtering:\")\n",
    "    if start_date is not None:\n",
    "        print(f\"  Start date: {start_date}\")\n",
    "    if end_date is not None:\n",
    "        print(f\"  End date: {end_date}\")\n",
    "    print(f\"  Original records: {original_count}\")\n",
    "    print(f\"  Filtered records: {len(df)} ({len(df)/original_count*100:.1f}% retained)\")\n",
    "    \n",
    "    return df"
   ],
   "id": "189120c123e833e4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data",
   "id": "16770055ed9fabad"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-04T23:12:46.315311Z",
     "start_time": "2025-05-04T23:11:45.176059Z"
    }
   },
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "df_clean = load_and_clean_data(\"reddit_opinion_ru_ua.csv\")\n",
    "min_date, max_date = analyze_post_dates(df_clean)\n",
    "cutoff_date = max_date - timedelta(days=10)\n",
    "\n",
    "df_recent = filter_by_date(df_clean, start_date=cutoff_date)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from reddit_opinion_ru_ua.csv...\n",
      "Original data shape: (5168018, 24)\n",
      "Data shape after cleaning: (766897, 24)\n",
      "Date filtering:\n",
      "  Start date: 2025-04-19 11:00:47\n",
      "  Original records: 766897\n",
      "  Filtered records: 41732 (5.4% retained)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:12:47.096982Z",
     "start_time": "2025-05-04T23:12:47.068365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "todrop = [\"comment_id\", \"created_time\",\"post_id\",\"user_is_verified\",\"user_account_created_time\", \"user_awardee_karma\", \"user_awarder_karma\", \"user_comment_karma\", \"user_link_karma\", \"post_created_time\"]\n",
    "df_recent.drop(todrop, axis=1, inplace=True)\n",
    "df_recent"
   ],
   "id": "80ce2289a8e5840c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brand\\AppData\\Local\\Temp\\ipykernel_16632\\2139921290.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recent.drop(todrop, axis=1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       score                                          self_text  \\\n",
       "0          1  I'd have to agree that it's hard to shop for m...   \n",
       "1          1  They don't, so you don't have to worry about t...   \n",
       "2          1  Trump is just buying time.  He won't do shit t...   \n",
       "3          1  They are being randomly called up for military...   \n",
       "4          1  Most of your assumptions here are wrong.\\n\\nFi...   \n",
       "...      ...                                                ...   \n",
       "98869     72                    Someone has been playing Metro…   \n",
       "98884      4       Time for Europe to take more responsibility.   \n",
       "98991    425  Whoever mixed the music in this video clearly ...   \n",
       "99003    850               Russia: I choo-choo-choose violence.   \n",
       "99048    917  So in 2025 we’ve got Russian horse logistics c...   \n",
       "\n",
       "                   subreddit           author_name  controversiality  ups  \\\n",
       "0                AskARussian              rsaachit                 0    1   \n",
       "1                     europe            potatolulz                 0    1   \n",
       "2      UkraineWarVideoReport  Many-Cartographer-45                 0    1   \n",
       "3                  worldnews                 Corka                 0    1   \n",
       "4                  worldnews           LeSygneNoir                 0    1   \n",
       "...                      ...                   ...               ...  ...   \n",
       "98869          CombatFootage      GallahadTheGreat                 0   72   \n",
       "98884  UkraineWarVideoReport    Still_Internet9670                 0    4   \n",
       "98991          CombatFootage                helgur                 0  425   \n",
       "99003          CombatFootage          DasFunktopus                 0  850   \n",
       "99048          CombatFootage  Dangerous_Horse_2794                 0  917   \n",
       "\n",
       "       downs  user_total_karma  post_score  \\\n",
       "0          0            2272.0           8   \n",
       "1          0          605528.0         590   \n",
       "2          0            2492.0         134   \n",
       "3          0          137057.0        2185   \n",
       "4          0          212668.0        2185   \n",
       "...      ...               ...         ...   \n",
       "98869      0           11439.0        4279   \n",
       "98884      0            2747.0         233   \n",
       "98991      0           69011.0        4279   \n",
       "99003      0           48910.0        4279   \n",
       "99048      0            2037.0        4279   \n",
       "\n",
       "                                          post_self_text  \\\n",
       "0      hello!! I’m currently trying to come up with g...   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "98869                                                NaN   \n",
       "98884                                                NaN   \n",
       "98991                                                NaN   \n",
       "99003                                                NaN   \n",
       "99048                                                NaN   \n",
       "\n",
       "                                              post_title  post_upvote_ratio  \\\n",
       "0               Gifts for Russian man - from an American               0.78   \n",
       "1      Zelensky dismisses Putin’s declaration of a 72...               0.98   \n",
       "2      The real Putin is now clear to Trump - and his...               0.95   \n",
       "3      Russia has lost over 950,000 soldiers since Fe...               0.97   \n",
       "4      Russia has lost over 950,000 soldiers since Fe...               0.97   \n",
       "...                                                  ...                ...   \n",
       "98869  The most unusual piece of equipment used by th...               0.99   \n",
       "98884  Trump administration not discussing new aid pa...               0.95   \n",
       "98991  The most unusual piece of equipment used by th...               0.99   \n",
       "99003  The most unusual piece of equipment used by th...               0.99   \n",
       "99048  The most unusual piece of equipment used by th...               0.99   \n",
       "\n",
       "       post_thumbs_ups  post_total_awards_received  \n",
       "0                    8                           0  \n",
       "1                  590                           0  \n",
       "2                  134                           0  \n",
       "3                 2185                           0  \n",
       "4                 2185                           0  \n",
       "...                ...                         ...  \n",
       "98869             4279                           0  \n",
       "98884              233                           0  \n",
       "98991             4279                           0  \n",
       "99003             4279                           0  \n",
       "99048             4279                           0  \n",
       "\n",
       "[41732 rows x 14 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author_name</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>user_total_karma</th>\n",
       "      <th>post_score</th>\n",
       "      <th>post_self_text</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_upvote_ratio</th>\n",
       "      <th>post_thumbs_ups</th>\n",
       "      <th>post_total_awards_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I'd have to agree that it's hard to shop for m...</td>\n",
       "      <td>AskARussian</td>\n",
       "      <td>rsaachit</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>8</td>\n",
       "      <td>hello!! I’m currently trying to come up with g...</td>\n",
       "      <td>Gifts for Russian man - from an American</td>\n",
       "      <td>0.78</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>They don't, so you don't have to worry about t...</td>\n",
       "      <td>europe</td>\n",
       "      <td>potatolulz</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>605528.0</td>\n",
       "      <td>590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zelensky dismisses Putin’s declaration of a 72...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Trump is just buying time.  He won't do shit t...</td>\n",
       "      <td>UkraineWarVideoReport</td>\n",
       "      <td>Many-Cartographer-45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The real Putin is now clear to Trump - and his...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>They are being randomly called up for military...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>Corka</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>137057.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russia has lost over 950,000 soldiers since Fe...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Most of your assumptions here are wrong.\\n\\nFi...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>LeSygneNoir</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>212668.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russia has lost over 950,000 soldiers since Fe...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98869</th>\n",
       "      <td>72</td>\n",
       "      <td>Someone has been playing Metro…</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>GallahadTheGreat</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>11439.0</td>\n",
       "      <td>4279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The most unusual piece of equipment used by th...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98884</th>\n",
       "      <td>4</td>\n",
       "      <td>Time for Europe to take more responsibility.</td>\n",
       "      <td>UkraineWarVideoReport</td>\n",
       "      <td>Still_Internet9670</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2747.0</td>\n",
       "      <td>233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trump administration not discussing new aid pa...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98991</th>\n",
       "      <td>425</td>\n",
       "      <td>Whoever mixed the music in this video clearly ...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>helgur</td>\n",
       "      <td>0</td>\n",
       "      <td>425</td>\n",
       "      <td>0</td>\n",
       "      <td>69011.0</td>\n",
       "      <td>4279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The most unusual piece of equipment used by th...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99003</th>\n",
       "      <td>850</td>\n",
       "      <td>Russia: I choo-choo-choose violence.</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>DasFunktopus</td>\n",
       "      <td>0</td>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>48910.0</td>\n",
       "      <td>4279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The most unusual piece of equipment used by th...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99048</th>\n",
       "      <td>917</td>\n",
       "      <td>So in 2025 we’ve got Russian horse logistics c...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>Dangerous_Horse_2794</td>\n",
       "      <td>0</td>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "      <td>2037.0</td>\n",
       "      <td>4279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The most unusual piece of equipment used by th...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41732 rows × 14 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:12:47.471186Z",
     "start_time": "2025-05-04T23:12:47.445925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get basic information\n",
    "print(\"Number of posts:\", len(df_recent))\n",
    "print(\"All subreddits:\")\n",
    "pd.DataFrame(df_recent.subreddit.explode().unique())"
   ],
   "id": "42ce1e145d402330",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts: 41732\n",
      "All subreddits:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                        0\n",
       "0             AskARussian\n",
       "1                  europe\n",
       "2   UkraineWarVideoReport\n",
       "3               worldnews\n",
       "4     UkraineRussiaReport\n",
       "5              conspiracy\n",
       "6                 ukraine\n",
       "7      ANormalDayInRussia\n",
       "8       UkrainianConflict\n",
       "9      russiawarinukraine\n",
       "10     NonCredibleDefense\n",
       "11      UkraineWarReports\n",
       "12  UkraineInvasionVideos\n",
       "13           MilitaryPorn\n",
       "14          CombatFootage\n",
       "15              AskReddit\n",
       "16   RussiaUkraineWar2022\n",
       "17                   news\n",
       "18           WayOfTheBern\n",
       "19               politics\n",
       "20             EndlessWar\n",
       "21        FreedomofRussia\n",
       "22        UkraineConflict\n",
       "23         LoveForUkraine\n",
       "24               Military\n",
       "25         UkraineWarRoom\n",
       "26             neoliberal\n",
       "27           Conservative\n",
       "28   volunteersForUkraine\n",
       "29            geopolitics\n",
       "30                 france\n",
       "31           RussiaDenies\n",
       "32                ukraina\n",
       "33            UkrainePics"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskARussian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UkraineWarVideoReport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UkraineRussiaReport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>conspiracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ANormalDayInRussia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UkrainianConflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>russiawarinukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NonCredibleDefense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UkraineWarReports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UkraineInvasionVideos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MilitaryPorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CombatFootage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RussiaUkraineWar2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WayOfTheBern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EndlessWar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FreedomofRussia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UkraineConflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LoveForUkraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>UkraineWarRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>neoliberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>volunteersForUkraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>geopolitics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RussiaDenies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ukraina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>UkrainePics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set up for topic modeling and sentiment analysis for comments, posts, and post titles",
   "id": "a3abd9af5e25d4ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:12:50.825749Z",
     "start_time": "2025-05-04T23:12:47.584438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt_tab\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "def preprocess_one_doc(text: str, lower: bool, punct: bool, stop: bool, stem: bool):\n",
    "    puncts = set(string.punctuation)\n",
    "    puncts.add(\"...\") # punct does not contain ellipses\n",
    "    puncts.add(\"…\")\n",
    "    puncts.add(\"===\")\n",
    "    puncts.add(\"—\")\n",
    "    puncts.add(\"–\")\n",
    "    puncts.add(\"“\")\n",
    "    puncts.add(\"”\")\n",
    "    puncts.add(\"’\")\n",
    "    puncts.add(\"‘\")\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    # stops.add(\"\")\n",
    "    \n",
    "    \n",
    "    # Lowercase the words depending on sentiment or topic modeling\n",
    "    if lower:\n",
    "        step0 = text.lower()\n",
    "    else:\n",
    "        step0 = text\n",
    "    step1 = word_tokenize(step0)\n",
    "    \n",
    "    \n",
    "    if punct:\n",
    "        step2 = \"\".join([ch for ch in \" \".join(step1) if ch not in puncts]).split()\n",
    "    else:\n",
    "        step2 = step1\n",
    "        \n",
    "        \n",
    "    \n",
    "    if stop:\n",
    "        # Remove stopwords\n",
    "        step3 = [token for token in step2\n",
    "                    if token not in stops # drop stopwords\n",
    "                    # and len(token) > 2 # drop words of insignificant length\n",
    "                    and (not token.startswith(\"http\"))] # drop links\n",
    "    else:\n",
    "        step3 = step2\n",
    "        \n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        step4 = [stemmer.stem(i) for i in step3]\n",
    "    else:\n",
    "        step4 = step3\n",
    "        \n",
    "    return step4\n",
    "\n",
    "from gensim import corpora, models\n",
    "\n",
    "def make_dictionary(alltexts):\n",
    "    d = corpora.Dictionary(alltexts)\n",
    "    d.filter_extremes(no_below=5, no_above=0.3) # Keep words that are in more than 5 documents, but not in more than a third of all documents\n",
    "    d.compactify()\n",
    "    return d\n",
    "\n",
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = RANDOM_STATE\n",
    "\n",
    "def filter_english(text):\n",
    "    try:\n",
    "        return detect(text) == \"en\"\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def make_all_components(df, text_column_name):\n",
    "    # Drop all missing values\n",
    "    dfc = df.copy()\n",
    "    dfc.dropna(subset=[text_column_name], inplace=True)\n",
    "    \n",
    "    # Filter non-english text\n",
    "    is_english = dfc[text_column_name].apply(filter_english)\n",
    "    dfc = dfc[is_english]\n",
    "    \n",
    "    # Create with standard preprocessing\n",
    "    preprocessed = dfc[text_column_name].apply(lambda x: preprocess_one_doc(x, lower=True, stop=True, punct=True, stem=True)) # Preprocess all docs\n",
    "    dictionary = make_dictionary(preprocessed.tolist()) # Use list of lists of strings\n",
    "    corpus = [dictionary.doc2bow(text) for text in preprocessed.tolist()] # bag of words representation of documents\n",
    "    return preprocessed, dictionary, corpus"
   ],
   "id": "e3ce9e99aa141aca",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:21:06.449134Z",
     "start_time": "2025-05-04T23:12:50.869432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create with standard preprocessing\n",
    "preprocessed_comments, dictionary_comments, corpus_comments = make_all_components(df_recent, \"self_text\")\n",
    "preprocessed_post_content, dictionary_post_content, corpus_post_content = make_all_components(df_recent, \"post_self_text\")\n",
    "preprocessed_title, dictionary_title, corpus_title = make_all_components(df_recent, \"post_title\")"
   ],
   "id": "c55303aacf345955",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:21:06.495799Z",
     "start_time": "2025-05-04T23:21:06.487963Z"
    }
   },
   "cell_type": "code",
   "source": "preprocessed_comments",
   "id": "e8147f7807cbddb5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [agre, hard, shop, men, unless, nich, hobbi, l...\n",
       "1                                          [nt, nt, worri]\n",
       "2        [trump, buy, time, wo, nt, shit, help, defeat,...\n",
       "3        [randomli, call, militari, servic, period, one...\n",
       "4        [assumpt, wrong, first, consid, overal, size, ...\n",
       "                               ...                        \n",
       "98869                                [someon, play, metro]\n",
       "98884                         [time, europ, take, respons]\n",
       "98991    [whoever, mix, music, video, clearli, miss, go...\n",
       "99003                     [russia, choochoochoos, violenc]\n",
       "99048    [2025, got, russian, hors, logist, convoy, lar...\n",
       "Name: self_text, Length: 38171, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate to find best number of topics",
   "id": "fcf9da0fb2263625"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:21:08.130517Z",
     "start_time": "2025-05-04T23:21:06.969426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Taken from https://medium.com/analytics-vidhya/topic-modeling-using-gensim-lda-in-python-48eaa2344920\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def eval_model(model, text, dic, corp):\n",
    "    # Compute Perplexity\n",
    "    perp = model.log_perplexity(corp)\n",
    "    # a measure of how good the model is. lower the better.\n",
    "    \n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=model, texts=text, dictionary=dic, coherence='c_v')\n",
    "    coherence = coherence_model_lda.get_coherence()\n",
    "    \n",
    "    return perp, coherence\n",
    "\n",
    "def plot_evals(perps, coherences, ks):\n",
    "    \n",
    "    fig = plt.figure(\"Perplexity and Coherence Analysis\", figsize=(8, 8))\n",
    "    axgrid = fig.add_gridspec(1, 2)\n",
    "    \n",
    "    ax1 = fig.add_subplot(axgrid[0, 0])\n",
    "    ax1.plot(ks, perps)\n",
    "    ax1.set_title(\"Number of topics vs Perplexity Score\")\n",
    "    ax1.set_xlabel(\"Number of Topics\")\n",
    "    ax1.set_ylabel(\"Perplexity Score\")\n",
    "    ax1.grid()\n",
    "    \n",
    "    ax2 = fig.add_subplot(axgrid[0, 1])\n",
    "    ax2.plot(ks, coherences)\n",
    "    ax2.set_title(\"Number of topics vs Coherence Score\")\n",
    "    ax2.set_xlabel(\"Number of Topics\")\n",
    "    ax2.set_ylabel(\"Coherence Score\")\n",
    "    ax2.grid()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def full_model_test_loop(text, corpus, dictionary):\n",
    "    ks = [1,2,3,4,5,6,7,8,9,10, 20, 30]\n",
    "    perps = []\n",
    "    coherences = []\n",
    "    for k in ks:\n",
    "        ldamodel = models.ldamodel.LdaModel(corpus, num_topics=k, id2word=dictionary, passes=20, random_state=RANDOM_STATE)\n",
    "        scores = eval_model(ldamodel, text.tolist(), dictionary, corpus)\n",
    "        perps.append(scores[0])\n",
    "        coherences.append(scores[1])\n",
    "    plot_evals(perps, coherences, ks)"
   ],
   "id": "ffc8ece3411fbfe4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:21:08.179909Z",
     "start_time": "2025-05-04T23:21:08.172414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(\"Comments eval:\")\n",
    "# full_model_test_loop(preprocessed_comments, corpus_comments, dictionary_comments)\n",
    "# print(\"Post Content eval:\")\n",
    "# full_model_test_loop(preprocessed_post_content, corpus_post_content, dictionary_post_content)\n",
    "# print(\"Post Title eval:\")\n",
    "# full_model_test_loop(preprocessed_title , corpus_title, dictionary_title)\n",
    "\n",
    "# 22 minutes to run all"
   ],
   "id": "a346c5d2f3e50ae0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Topic Modeling",
   "id": "d7495206ee602d2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:27:33.774754Z",
     "start_time": "2025-05-04T23:21:08.197562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ldamodel_comments = models.ldamodel.LdaModel(corpus_comments, num_topics=10, id2word=dictionary_comments, passes=20, random_state=RANDOM_STATE)\n",
    "ldamodel_post_content = models.ldamodel.LdaModel(corpus_post_content, num_topics=5, id2word=dictionary_post_content, passes=20, random_state=RANDOM_STATE)\n",
    "ldamodel_title = models.ldamodel.LdaModel(corpus_title, num_topics=20, id2word=dictionary_title, passes=20, random_state=RANDOM_STATE)\n",
    "\n",
    "# 6 min 30 sec"
   ],
   "id": "6dec4df67d883cf8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO: call eval_model to get the perplexity and coherence of the top k model and present them in table",
   "id": "b9d0b61ae41f9b30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:27:34.283481Z",
     "start_time": "2025-05-04T23:27:34.273881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Comment topics:\")\n",
    "ldamodel_comments.show_topics()"
   ],
   "id": "f0e5cfaa84ba6d46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment topics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.034*\"war\" + 0.033*\"day\" + 0.032*\"said\" + 0.029*\"gt\" + 0.021*\"end\" + 0.020*\"bomb\" + 0.019*\"one\" + 0.019*\"na\" + 0.014*\"gon\" + 0.014*\"moscow\"'),\n",
       " (1,\n",
       "  '0.064*\"ukrain\" + 0.050*\"russia\" + 0.020*\"nt\" + 0.020*\"war\" + 0.018*\"want\" + 0.018*\"would\" + 0.015*\"peac\" + 0.014*\"us\" + 0.012*\"putin\" + 0.012*\"give\"'),\n",
       " (2,\n",
       "  '0.085*\"fuck\" + 0.033*\"easter\" + 0.031*\"yeah\" + 0.026*\"amp\" + 0.020*\"god\" + 0.017*\"oh\" + 0.014*\"hour\" + 0.013*\"hear\" + 0.013*\"church\" + 0.013*\"pleas\"'),\n",
       " (3,\n",
       "  '0.031*\"kill\" + 0.026*\"thank\" + 0.018*\"orang\" + 0.017*\"shit\" + 0.014*\"peopl\" + 0.013*\"children\" + 0.011*\"say\" + 0.011*\"show\" + 0.010*\"red\" + 0.010*\"human\"'),\n",
       " (4,\n",
       "  '0.079*\"trump\" + 0.049*\"putin\" + 0.028*\"like\" + 0.020*\"look\" + 0.012*\"make\" + 0.010*\"presid\" + 0.010*\"zelenski\" + 0.009*\"play\" + 0.008*\"get\" + 0.008*\"biden\"'),\n",
       " (5,\n",
       "  '0.054*\"nt\" + 0.025*\"peopl\" + 0.017*\"say\" + 0.015*\"know\" + 0.015*\"think\" + 0.012*\"like\" + 0.011*\"would\" + 0.010*\"believ\" + 0.010*\"want\" + 0.010*\"american\"'),\n",
       " (6,\n",
       "  '0.027*\"year\" + 0.023*\"see\" + 0.020*\"time\" + 0.018*\"got\" + 0.015*\"love\" + 0.015*\"one\" + 0.014*\"hope\" + 0.014*\"get\" + 0.014*\"go\" + 0.012*\"ye\"'),\n",
       " (7,\n",
       "  '0.044*\"russian\" + 0.020*\"ukrainian\" + 0.020*\"drone\" + 0.019*\"use\" + 0.013*\"missil\" + 0.010*\"target\" + 0.009*\"attack\" + 0.008*\"train\" + 0.008*\"air\" + 0.007*\"militari\"'),\n",
       " (8,\n",
       "  '0.021*\"like\" + 0.011*\"peopl\" + 0.010*\"russian\" + 0.009*\"lot\" + 0.009*\"much\" + 0.009*\"also\" + 0.008*\"would\" + 0.008*\"use\" + 0.007*\"thing\" + 0.007*\"good\"'),\n",
       " (9,\n",
       "  '0.027*\"us\" + 0.021*\"russia\" + 0.018*\"countri\" + 0.012*\"state\" + 0.009*\"eu\" + 0.008*\"world\" + 0.008*\"war\" + 0.008*\"power\" + 0.008*\"china\" + 0.007*\"russian\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:27:34.623457Z",
     "start_time": "2025-05-04T23:27:34.614468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Post content topics:\")\n",
    "ldamodel_post_content.show_topics()"
   ],
   "id": "f8308c939e5c1dda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post content topics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.017*\"war\" + 0.012*\"trump\" + 0.012*\"video\" + 0.011*\"sourc\" + 0.010*\"ukrain\" + 0.010*\"us\" + 0.009*\"inform\" + 0.008*\"realiti\" + 0.008*\"document\" + 0.008*\"educ\"'),\n",
       " (1,\n",
       "  '0.012*\"would\" + 0.011*\"ukrain\" + 0.011*\"want\" + 0.008*\"like\" + 0.008*\"amp\" + 0.007*\"live\" + 0.007*\"peopl\" + 0.007*\"get\" + 0.007*\"ukrainian\" + 0.006*\"realli\"'),\n",
       " (2,\n",
       "  '0.011*\"would\" + 0.009*\"like\" + 0.009*\"nt\" + 0.009*\"lawn\" + 0.007*\"name\" + 0.006*\"peopl\" + 0.006*\"think\" + 0.005*\"said\" + 0.005*\"elect\" + 0.005*\"time\"'),\n",
       " (3,\n",
       "  '0.018*\"soldier\" + 0.010*\"ukrainian\" + 0.010*\"ukrain\" + 0.008*\"colombian\" + 0.008*\"one\" + 0.006*\"forc\" + 0.006*\"unit\" + 0.006*\"said\" + 0.006*\"gt\" + 0.005*\"drone\"'),\n",
       " (4,\n",
       "  '0.013*\"banksi\" + 0.011*\"nt\" + 0.008*\"artist\" + 0.007*\"would\" + 0.007*\"administr\" + 0.006*\"rob\" + 0.006*\"trump\" + 0.006*\"never\" + 0.005*\"work\" + 0.005*\"time\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:27:34.975071Z",
     "start_time": "2025-05-04T23:27:34.965586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Title topics:\")\n",
    "ldamodel_title.show_topics()"
   ],
   "id": "f99352b2466c1852",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title topics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  '0.133*\"russia\" + 0.082*\"hour\" + 0.078*\"fight\" + 0.065*\"offic\" + 0.062*\"time\" + 0.050*\"violat\" + 0.043*\"first\" + 0.042*\"offici\" + 0.034*\"admit\" + 0.032*\"troop\"'),\n",
       " (4,\n",
       "  '0.225*\"truce\" + 0.190*\"ceasefir\" + 0.078*\"ua\" + 0.074*\"sinc\" + 0.074*\"pov\" + 0.047*\"may\" + 0.041*\"announc\" + 0.026*\"territori\" + 0.022*\"includ\" + 0.018*\"order\"'),\n",
       " (19,\n",
       "  '0.119*\"claim\" + 0.078*\"air\" + 0.060*\"place\" + 0.058*\"back\" + 0.056*\"play\" + 0.048*\"within\" + 0.048*\"gener\" + 0.046*\"jet\" + 0.043*\"await\" + 0.040*\"true\"'),\n",
       " (15,\n",
       "  '0.105*\"attack\" + 0.093*\"moscow\" + 0.080*\"along\" + 0.072*\"join\" + 0.065*\"show\" + 0.049*\"pope\" + 0.049*\"nsfw\" + 0.046*\"negoti\" + 0.039*\"may\" + 0.034*\"9\"'),\n",
       " (11,\n",
       "  '0.099*\"trump\" + 0.081*\"peopl\" + 0.077*\"russia\" + 0.076*\"plan\" + 0.074*\"propos\" + 0.051*\"away\" + 0.046*\"reject\" + 0.045*\"one\" + 0.044*\"launch\" + 0.043*\"warn\"'),\n",
       " (18,\n",
       "  '0.245*\"putin\" + 0.128*\"war\" + 0.126*\"trump\" + 0.116*\"declar\" + 0.061*\"end\" + 0.048*\"call\" + 0.045*\"start\" + 0.033*\"donald\" + 0.032*\"say\" + 0.026*\"deal\"'),\n",
       " (9,\n",
       "  '0.080*\"right\" + 0.078*\"explos\" + 0.060*\"promis\" + 0.059*\"regim\" + 0.050*\"walk\" + 0.044*\"around\" + 0.043*\"car\" + 0.038*\"train\" + 0.027*\"chief\" + 0.027*\"us\"'),\n",
       " (17,\n",
       "  '0.105*\"russia\" + 0.087*\"rubio\" + 0.077*\"new\" + 0.071*\"fire\" + 0.054*\"think\" + 0.047*\"war\" + 0.041*\"would\" + 0.040*\"weapon\" + 0.039*\"sanction\" + 0.038*\"top\"'),\n",
       " (10,\n",
       "  '0.121*\"line\" + 0.095*\"soldier\" + 0.066*\"human\" + 0.065*\"armor\" + 0.063*\"hit\" + 0.042*\"injur\" + 0.040*\"insid\" + 0.036*\"near\" + 0.031*\"mine\" + 0.031*\"flag\"'),\n",
       " (12,\n",
       "  '0.379*\"‘\" + 0.122*\"stop\" + 0.085*\"putin\" + 0.051*\"tell\" + 0.039*\"latest\" + 0.034*\"integr\" + 0.031*\"famili\" + 0.031*\"polit\" + 0.018*\"european\" + 0.018*\"updat\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sentiment Analysis",
   "id": "b38d76ec33aa551a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:28:22.064441Z",
     "start_time": "2025-05-04T23:28:22.060899Z"
    }
   },
   "cell_type": "code",
   "source": "#TODO adapt to generic scores, include average pos, neg, neu scores, plot histogram of scores, plot distribution of compound scores",
   "id": "2adad60b440bfdb7",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:28:22.123194Z",
     "start_time": "2025-05-04T23:28:22.076411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def find_compound_sentiment(document):\n",
    "    sentences = sent_tokenize(document)\n",
    "    s = 0\n",
    "    for sentence in sentences:\n",
    "        sentiment = sid.polarity_scores(sentence)[\"compound\"]\n",
    "        s += sentiment\n",
    "    return s/len(sentences)\n",
    "    \n",
    "def find_all_topic_sentiments(corp, raws, model, refs):\n",
    "    dominant_topics = []\n",
    "    document_scores = []\n",
    "    corp_plus_raws = zip(corp, raws)\n",
    "    for bag, raw in corp_plus_raws:\n",
    "        topics = model.get_document_topics(bag)\n",
    "        dominant_topic = sorted(topics, key=lambda x: -x[1])[0][0]\n",
    "        dominant_topics.append(dominant_topic)\n",
    "        document_scores.append(find_compound_sentiment(raw))\n",
    "        \n",
    "    topic_sentiments = {}\n",
    "    topic_refs = {}\n",
    "    document_topic_score = list(zip(dominant_topics, document_scores, refs))\n",
    "    for i in range(k):\n",
    "        sentiments_in_topic = [sentiment for topic, sentiment, _ in document_topic_score if topic == i]\n",
    "        topic_sentiments[i] = sum(sentiments_in_topic)/len(sentiments_in_topic)\n",
    "        refs_in_topic = [refs for topic, _, refs in document_topic_score if topic == i]\n",
    "        topic_refs[i] = sum(refs_in_topic)/len(refs_in_topic)\n",
    "        \n",
    "    return [topic_sentiments, document_scores, topic_refs]"
   ],
   "id": "f69da25e1750478b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T23:28:22.790535Z",
     "start_time": "2025-05-04T23:28:22.492447Z"
    }
   },
   "cell_type": "code",
   "source": "topic_scores, dataset_scores, topic_nrefs = find_all_topic_sentiments(corpus, dataset[\"content\"], ldamodel, dataset[\"nrefs\"])",
   "id": "332401e1cfd1b731",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m topic_scores, dataset_scores, topic_nrefs \u001B[38;5;241m=\u001B[39m find_all_topic_sentiments(corpus, dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m], ldamodel, dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrefs\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
