{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T17:50:24.721636Z",
     "start_time": "2025-05-09T17:50:23.501268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get preprocessing methods from make_network.ipynb to keep consistent.\n",
    "RANDOM_STATE = 5664\n",
    "import os\n",
    "import pandas as pd\n",
    "def load_and_clean_data(filepath):\n",
    "    \"\"\"\n",
    "    Load Reddit data and remove duplicate user-subreddit combinations.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the CSV data file\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Cleaned dataframe with unique user-subreddit combinations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(filepath):\n",
    "            raise FileNotFoundError(f\"Data file not found: {filepath}\")\n",
    "            \n",
    "        # Load the dataset\n",
    "        print(f\"Loading data from {filepath}...\")\n",
    "        df = pd.read_csv(filepath)\n",
    "        print(f\"Original data shape: {df.shape}\")\n",
    "        \n",
    "        # Remove exact duplicates\n",
    "        df_unique = df.drop_duplicates().copy()\n",
    "        \n",
    "        print(f\"Data shape after removing exact duplicates: {df_unique.shape}\")\n",
    "        \n",
    "        return df_unique\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in load_and_clean_data: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "def analyze_post_dates(df):\n",
    "    # Convert post_created_time to datetime\n",
    "    df['post_created_time'] = pd.to_datetime(df['post_created_time'])\n",
    "    \n",
    "    # Get the earliest and latest dates\n",
    "    min_date = df['post_created_time'].min()\n",
    "    max_date = df['post_created_time'].max()\n",
    "    \n",
    "    return min_date, max_date\n",
    "\n",
    "def filter_by_date(df, start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Filter dataframe to include only posts within a specific date range.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame with 'post_created_time' column\n",
    "        start_date (str, datetime, optional): Keep posts on or after this date\n",
    "        end_date (str, datetime, optional): Keep posts on or before this date\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Filtered dataframe\n",
    "    \"\"\"\n",
    "    # Make sure post_created_time is datetime\n",
    "    if not pd.api.types.is_datetime64_dtype(df['post_created_time']):\n",
    "        df['post_created_time'] = pd.to_datetime(df['post_created_time'])\n",
    "    \n",
    "    original_count = len(df)\n",
    "    \n",
    "    # Apply date filters\n",
    "    if start_date is not None:\n",
    "        if isinstance(start_date, str):\n",
    "            start_date = pd.to_datetime(start_date)\n",
    "        df = df[df['post_created_time'] >= start_date]\n",
    "    \n",
    "    if end_date is not None:\n",
    "        if isinstance(end_date, str):\n",
    "            end_date = pd.to_datetime(end_date)\n",
    "        df = df[df['post_created_time'] <= end_date]\n",
    "    \n",
    "    # Report on filtering\n",
    "    print(f\"Date filtering:\")\n",
    "    if start_date is not None:\n",
    "        print(f\"  Start date: {start_date}\")\n",
    "    if end_date is not None:\n",
    "        print(f\"  End date: {end_date}\")\n",
    "    print(f\"  Original records: {original_count}\")\n",
    "    print(f\"  Filtered records: {len(df)} ({len(df)/original_count*100:.1f}% retained)\")\n",
    "    \n",
    "    return df"
   ],
   "id": "189120c123e833e4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data",
   "id": "16770055ed9fabad"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-09T17:51:46.680121Z",
     "start_time": "2025-05-09T17:50:24.735896Z"
    }
   },
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "df_clean = load_and_clean_data(\"reddit_opinion_ru_ua.csv\")\n",
    "min_date, max_date = analyze_post_dates(df_clean)\n",
    "cutoff_date = max_date - timedelta(days=5) # Get enough to be meaningful, but not too many to be impractical to run\n",
    "\n",
    "df_recent = filter_by_date(df_clean, start_date=cutoff_date)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from reddit_opinion_ru_ua.csv...\n",
      "Original data shape: (5168018, 24)\n",
      "Data shape after removing exact duplicates: (5168018, 24)\n",
      "Date filtering:\n",
      "  Start date: 2025-04-24 11:00:47\n",
      "  Original records: 5168018\n",
      "  Filtered records: 50011 (1.0% retained)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T17:51:47.177337Z",
     "start_time": "2025-05-09T17:51:47.109411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "todrop = [\"comment_id\", \"created_time\",\"post_id\",\"user_is_verified\",\"user_account_created_time\", \"user_awardee_karma\", \"user_awarder_karma\", \"user_comment_karma\", \"user_link_karma\", \"post_created_time\"]\n",
    "df_recent.drop(todrop, axis=1).copy()\n",
    "df_recent"
   ],
   "id": "80ce2289a8e5840c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      comment_id  score                                          self_text  \\\n",
       "0        mpn18ju      1  I'd have to agree that it's hard to shop for m...   \n",
       "1        mpn188l      1  They don't, so you don't have to worry about t...   \n",
       "2        mpn16la      1  Trump is just buying time.  He won't do shit t...   \n",
       "3        mpn14md      1  They are being randomly called up for military...   \n",
       "4        mpn141c      1  Most of your assumptions here are wrong.\\n\\nFi...   \n",
       "...          ...    ...                                                ...   \n",
       "53486    morpkzi     23                                            Krasnov   \n",
       "53525    morp8gl      1  Would we give up a section of the US to secure...   \n",
       "53528    morp7gg      7  good to see Poland and Ukraine coming together...   \n",
       "53588    morofnx      2  Pinged EUROPE ([subscribe](https://reddit.com/...   \n",
       "53590    morofec      8  !ping POLAND&amp;EUROPE\\n\\nSo glad Poland and ...   \n",
       "\n",
       "                   subreddit         created_time  post_id  \\\n",
       "0                AskARussian  2025-04-29 11:08:21  1kaa04k   \n",
       "1                     europe  2025-04-29 11:08:16  1kajrb4   \n",
       "2      UkraineWarVideoReport  2025-04-29 11:07:55  1kajrn6   \n",
       "3                  worldnews  2025-04-29 11:07:29  1kaipov   \n",
       "4                  worldnews  2025-04-29 11:07:21  1kaipov   \n",
       "...                      ...                  ...      ...   \n",
       "53486                 europe  2025-04-24 11:16:13  1k6pk64   \n",
       "53525            geopolitics  2025-04-24 11:13:37  1k6phqk   \n",
       "53528              worldnews  2025-04-24 11:13:25  1k6ph7j   \n",
       "53588             neoliberal  2025-04-24 11:07:22  1k6pgt2   \n",
       "53590             neoliberal  2025-04-24 11:07:18  1k6pgt2   \n",
       "\n",
       "                author_name  controversiality  ups  downs  ...  \\\n",
       "0                  rsaachit                 0    1      0  ...   \n",
       "1                potatolulz                 0    1      0  ...   \n",
       "2      Many-Cartographer-45                 0    1      0  ...   \n",
       "3                     Corka                 0    1      0  ...   \n",
       "4               LeSygneNoir                 0    1      0  ...   \n",
       "...                     ...               ...  ...    ...  ...   \n",
       "53486             davidd679                 0   23      0  ...   \n",
       "53525           UnusualAir1                 0    1      0  ...   \n",
       "53528  Appropriate_Age_8918                 0    7      0  ...   \n",
       "53588              groupbot                 0    2      0  ...   \n",
       "53590           BubsyFanboy                 0    8      0  ...   \n",
       "\n",
       "       user_link_karma user_comment_karma  user_total_karma  post_score  \\\n",
       "0               1462.0              810.0            2272.0           8   \n",
       "1              11179.0           594349.0          605528.0         590   \n",
       "2                  1.0             2491.0            2492.0         134   \n",
       "3                789.0           136268.0          137057.0        2185   \n",
       "4              32188.0           180480.0          212668.0        2185   \n",
       "...                ...                ...               ...         ...   \n",
       "53486              1.0             1342.0            1343.0        4204   \n",
       "53525         163647.0           183516.0          347163.0         265   \n",
       "53528             70.0              725.0             795.0         116   \n",
       "53588              3.0           137119.0          137122.0          99   \n",
       "53590         527180.0           794384.0         1321564.0          99   \n",
       "\n",
       "                                          post_self_text  \\\n",
       "0      hello!! I’m currently trying to come up with g...   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "53486                                                NaN   \n",
       "53525  It should be argued that Trump himself is prol...   \n",
       "53528                                                NaN   \n",
       "53588  Poland and Ukraine have issued a joint stateme...   \n",
       "53590  Poland and Ukraine have issued a joint stateme...   \n",
       "\n",
       "                                              post_title  post_upvote_ratio  \\\n",
       "0               Gifts for Russian man - from an American               0.78   \n",
       "1      Zelensky dismisses Putin’s declaration of a 72...               0.98   \n",
       "2      The real Putin is now clear to Trump - and his...               0.95   \n",
       "3      Russia has lost over 950,000 soldiers since Fe...               0.97   \n",
       "4      Russia has lost over 950,000 soldiers since Fe...               0.97   \n",
       "...                                                  ...                ...   \n",
       "53486  Trump’s Plan to Sell Out Ukraine to Russia. Hi...               0.98   \n",
       "53525  Trump says Zelenskyy is prolonging war in Ukra...               0.89   \n",
       "53528  Poland and Ukraine jointly condemn vandalism o...               0.92   \n",
       "53588  Poland and Ukraine jointly condemn vandalism o...               0.98   \n",
       "53590  Poland and Ukraine jointly condemn vandalism o...               0.98   \n",
       "\n",
       "       post_thumbs_ups post_total_awards_received   post_created_time  \n",
       "0                    8                          0 2025-04-28 23:37:58  \n",
       "1                  590                          0 2025-04-29 09:27:03  \n",
       "2                  134                          0 2025-04-29 09:27:45  \n",
       "3                 2185                          0 2025-04-29 08:07:53  \n",
       "4                 2185                          0 2025-04-29 08:07:53  \n",
       "...                ...                        ...                 ...  \n",
       "53486             4204                          0 2025-04-24 11:12:13  \n",
       "53525              265                          0 2025-04-24 11:08:13  \n",
       "53528              116                          0 2025-04-24 11:07:22  \n",
       "53588               99                          0 2025-04-24 11:06:42  \n",
       "53590               99                          0 2025-04-24 11:06:42  \n",
       "\n",
       "[50011 rows x 24 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "      <th>post_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>...</th>\n",
       "      <th>user_link_karma</th>\n",
       "      <th>user_comment_karma</th>\n",
       "      <th>user_total_karma</th>\n",
       "      <th>post_score</th>\n",
       "      <th>post_self_text</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_upvote_ratio</th>\n",
       "      <th>post_thumbs_ups</th>\n",
       "      <th>post_total_awards_received</th>\n",
       "      <th>post_created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mpn18ju</td>\n",
       "      <td>1</td>\n",
       "      <td>I'd have to agree that it's hard to shop for m...</td>\n",
       "      <td>AskARussian</td>\n",
       "      <td>2025-04-29 11:08:21</td>\n",
       "      <td>1kaa04k</td>\n",
       "      <td>rsaachit</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>8</td>\n",
       "      <td>hello!! I’m currently trying to come up with g...</td>\n",
       "      <td>Gifts for Russian man - from an American</td>\n",
       "      <td>0.78</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-28 23:37:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mpn188l</td>\n",
       "      <td>1</td>\n",
       "      <td>They don't, so you don't have to worry about t...</td>\n",
       "      <td>europe</td>\n",
       "      <td>2025-04-29 11:08:16</td>\n",
       "      <td>1kajrb4</td>\n",
       "      <td>potatolulz</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11179.0</td>\n",
       "      <td>594349.0</td>\n",
       "      <td>605528.0</td>\n",
       "      <td>590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zelensky dismisses Putin’s declaration of a 72...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>590</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29 09:27:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mpn16la</td>\n",
       "      <td>1</td>\n",
       "      <td>Trump is just buying time.  He won't do shit t...</td>\n",
       "      <td>UkraineWarVideoReport</td>\n",
       "      <td>2025-04-29 11:07:55</td>\n",
       "      <td>1kajrn6</td>\n",
       "      <td>Many-Cartographer-45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The real Putin is now clear to Trump - and his...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29 09:27:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mpn14md</td>\n",
       "      <td>1</td>\n",
       "      <td>They are being randomly called up for military...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2025-04-29 11:07:29</td>\n",
       "      <td>1kaipov</td>\n",
       "      <td>Corka</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>789.0</td>\n",
       "      <td>136268.0</td>\n",
       "      <td>137057.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russia has lost over 950,000 soldiers since Fe...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2185</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29 08:07:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mpn141c</td>\n",
       "      <td>1</td>\n",
       "      <td>Most of your assumptions here are wrong.\\n\\nFi...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2025-04-29 11:07:21</td>\n",
       "      <td>1kaipov</td>\n",
       "      <td>LeSygneNoir</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32188.0</td>\n",
       "      <td>180480.0</td>\n",
       "      <td>212668.0</td>\n",
       "      <td>2185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russia has lost over 950,000 soldiers since Fe...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2185</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29 08:07:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53486</th>\n",
       "      <td>morpkzi</td>\n",
       "      <td>23</td>\n",
       "      <td>Krasnov</td>\n",
       "      <td>europe</td>\n",
       "      <td>2025-04-24 11:16:13</td>\n",
       "      <td>1k6pk64</td>\n",
       "      <td>davidd679</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>4204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trump’s Plan to Sell Out Ukraine to Russia. Hi...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4204</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-24 11:12:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53525</th>\n",
       "      <td>morp8gl</td>\n",
       "      <td>1</td>\n",
       "      <td>Would we give up a section of the US to secure...</td>\n",
       "      <td>geopolitics</td>\n",
       "      <td>2025-04-24 11:13:37</td>\n",
       "      <td>1k6phqk</td>\n",
       "      <td>UnusualAir1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>163647.0</td>\n",
       "      <td>183516.0</td>\n",
       "      <td>347163.0</td>\n",
       "      <td>265</td>\n",
       "      <td>It should be argued that Trump himself is prol...</td>\n",
       "      <td>Trump says Zelenskyy is prolonging war in Ukra...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-24 11:08:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53528</th>\n",
       "      <td>morp7gg</td>\n",
       "      <td>7</td>\n",
       "      <td>good to see Poland and Ukraine coming together...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2025-04-24 11:13:25</td>\n",
       "      <td>1k6ph7j</td>\n",
       "      <td>Appropriate_Age_8918</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poland and Ukraine jointly condemn vandalism o...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-24 11:07:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53588</th>\n",
       "      <td>morofnx</td>\n",
       "      <td>2</td>\n",
       "      <td>Pinged EUROPE ([subscribe](https://reddit.com/...</td>\n",
       "      <td>neoliberal</td>\n",
       "      <td>2025-04-24 11:07:22</td>\n",
       "      <td>1k6pgt2</td>\n",
       "      <td>groupbot</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>137119.0</td>\n",
       "      <td>137122.0</td>\n",
       "      <td>99</td>\n",
       "      <td>Poland and Ukraine have issued a joint stateme...</td>\n",
       "      <td>Poland and Ukraine jointly condemn vandalism o...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-24 11:06:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53590</th>\n",
       "      <td>morofec</td>\n",
       "      <td>8</td>\n",
       "      <td>!ping POLAND&amp;amp;EUROPE\\n\\nSo glad Poland and ...</td>\n",
       "      <td>neoliberal</td>\n",
       "      <td>2025-04-24 11:07:18</td>\n",
       "      <td>1k6pgt2</td>\n",
       "      <td>BubsyFanboy</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>527180.0</td>\n",
       "      <td>794384.0</td>\n",
       "      <td>1321564.0</td>\n",
       "      <td>99</td>\n",
       "      <td>Poland and Ukraine have issued a joint stateme...</td>\n",
       "      <td>Poland and Ukraine jointly condemn vandalism o...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-24 11:06:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50011 rows × 24 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T17:51:47.272017Z",
     "start_time": "2025-05-09T17:51:47.246883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get basic information\n",
    "print(\"Number of comments:\", len(df_recent))\n",
    "print(\"All subreddits:\")\n",
    "pd.DataFrame(df_recent.subreddit.explode().unique())"
   ],
   "id": "42ce1e145d402330",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of comments: 50011\n",
      "All subreddits:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                        0\n",
       "0             AskARussian\n",
       "1                  europe\n",
       "2   UkraineWarVideoReport\n",
       "3               worldnews\n",
       "4     UkraineRussiaReport\n",
       "5              conspiracy\n",
       "6                 ukraine\n",
       "7      ANormalDayInRussia\n",
       "8       UkrainianConflict\n",
       "9      russiawarinukraine\n",
       "10     NonCredibleDefense\n",
       "11      UkraineWarReports\n",
       "12  UkraineInvasionVideos\n",
       "13           MilitaryPorn\n",
       "14          CombatFootage\n",
       "15              AskReddit\n",
       "16   RussiaUkraineWar2022\n",
       "17                   news\n",
       "18           WayOfTheBern\n",
       "19               politics\n",
       "20             EndlessWar\n",
       "21        FreedomofRussia\n",
       "22        UkraineConflict\n",
       "23         LoveForUkraine\n",
       "24               Military\n",
       "25         UkraineWarRoom\n",
       "26             neoliberal\n",
       "27           Conservative\n",
       "28   volunteersForUkraine\n",
       "29            geopolitics\n",
       "30                 france\n",
       "31                ukraina"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskARussian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UkraineWarVideoReport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UkraineRussiaReport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>conspiracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ANormalDayInRussia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UkrainianConflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>russiawarinukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NonCredibleDefense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UkraineWarReports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UkraineInvasionVideos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MilitaryPorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CombatFootage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RussiaUkraineWar2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WayOfTheBern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EndlessWar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FreedomofRussia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UkraineConflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LoveForUkraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>UkraineWarRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>neoliberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>volunteersForUkraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>geopolitics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ukraina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set up for topic modeling and sentiment analysis for comments, posts, and post titles",
   "id": "a3abd9af5e25d4ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T17:51:50.480527Z",
     "start_time": "2025-05-09T17:51:47.404203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt_tab\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "def preprocess_one_doc(text: str, lower: bool, punct: bool, stop: bool, stem: bool):\n",
    "    puncts = set(string.punctuation)\n",
    "    puncts.add(\"...\") # punct does not contain ellipses\n",
    "    puncts.add(\"…\")\n",
    "    puncts.add(\"===\")\n",
    "    puncts.add(\"—\")\n",
    "    puncts.add(\"–\")\n",
    "    puncts.add(\"“\")\n",
    "    puncts.add(\"”\")\n",
    "    puncts.add(\"’\")\n",
    "    puncts.add(\"‘\")\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    # stops.add(\"\")\n",
    "    \n",
    "    \n",
    "    # Lowercase the words depending on sentiment or topic modeling\n",
    "    if lower:\n",
    "        step0 = text.lower()\n",
    "    else:\n",
    "        step0 = text\n",
    "    step1 = word_tokenize(step0)\n",
    "    \n",
    "    \n",
    "    if punct:\n",
    "        step2 = \"\".join([ch for ch in \" \".join(step1) if ch not in puncts]).split()\n",
    "    else:\n",
    "        step2 = step1\n",
    "        \n",
    "        \n",
    "    \n",
    "    if stop:\n",
    "        # Remove stopwords\n",
    "        step3 = [token for token in step2\n",
    "                    if token not in stops # drop stopwords\n",
    "                    # and len(token) > 2 # drop words of insignificant length\n",
    "                    and (not token.startswith(\"http\"))] # drop links\n",
    "    else:\n",
    "        step3 = step2\n",
    "        \n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        step4 = [stemmer.stem(i) for i in step3]\n",
    "    else:\n",
    "        step4 = step3\n",
    "        \n",
    "    return step4\n",
    "\n",
    "from gensim import corpora, models\n",
    "\n",
    "def make_dictionary(alltexts):\n",
    "    d = corpora.Dictionary(alltexts)\n",
    "    d.filter_extremes(no_below=5, no_above=0.3) # Keep words that are in more than 5 documents, but not in more than a third of all documents\n",
    "    d.compactify()\n",
    "    return d\n",
    "\n",
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = RANDOM_STATE\n",
    "\n",
    "def filter_english(text):\n",
    "    try:\n",
    "        return detect(text) == \"en\"\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def clean_column(df, text_column_name):\n",
    "    # Drop all missing values\n",
    "    dfc = df.copy()\n",
    "    dfc.dropna(subset=[text_column_name], inplace=True)\n",
    "    \n",
    "    # Filter non-english text\n",
    "    is_english = dfc[text_column_name].apply(filter_english)\n",
    "    dfc = dfc[is_english]\n",
    "    return dfc\n",
    "\n",
    "def make_all_components(df, text_column_name):\n",
    "    dfc = clean_column(df, text_column_name)\n",
    "    \n",
    "    # Create with standard preprocessing\n",
    "    preprocessed = dfc[text_column_name].apply(lambda x: preprocess_one_doc(x, lower=True, stop=True, punct=True, stem=True)) # Preprocess all docs\n",
    "    dictionary = make_dictionary(preprocessed.tolist()) # Use list of lists of strings\n",
    "    corpus = [dictionary.doc2bow(text) for text in preprocessed.tolist()] # bag of words representation of documents\n",
    "    return preprocessed, dictionary, corpus"
   ],
   "id": "e3ce9e99aa141aca",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:01:49.270373Z",
     "start_time": "2025-05-09T17:51:50.534769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create with standard preprocessing\n",
    "print(\"Processing comments\")\n",
    "preprocessed_comments, dictionary_comments, corpus_comments = make_all_components(df_recent, \"self_text\")\n",
    "print(\"Processing post content\")\n",
    "preprocessed_post_content, dictionary_post_content, corpus_post_content = make_all_components(df_recent, \"post_self_text\")\n",
    "print(\"Processing titles\")\n",
    "preprocessed_title, dictionary_title, corpus_title = make_all_components(df_recent, \"post_title\")"
   ],
   "id": "c55303aacf345955",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing comments\n",
      "Processing post content\n",
      "Processing titles\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate to find best number of topics",
   "id": "fcf9da0fb2263625"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:01:50.183559Z",
     "start_time": "2025-05-09T18:01:49.329366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Taken from https://medium.com/analytics-vidhya/topic-modeling-using-gensim-lda-in-python-48eaa2344920\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def eval_model(model, text, corp, dic):\n",
    "    # Compute Perplexity\n",
    "    perp = model.log_perplexity(corp)\n",
    "    # a measure of how good the model is. lower the better.\n",
    "    \n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=model, texts=text, dictionary=dic, coherence='c_v')\n",
    "    coherence = coherence_model_lda.get_coherence()\n",
    "    \n",
    "    return perp, coherence\n",
    "\n",
    "def plot_evals(perps, coherences, ks):\n",
    "    \n",
    "    fig = plt.figure(\"Perplexity and Coherence Analysis\", figsize=(8, 8))\n",
    "    axgrid = fig.add_gridspec(1, 2)\n",
    "    \n",
    "    ax1 = fig.add_subplot(axgrid[0, 0])\n",
    "    ax1.plot(ks, perps)\n",
    "    ax1.set_title(\"Number of topics vs Perplexity Score\")\n",
    "    ax1.set_xlabel(\"Number of Topics\")\n",
    "    ax1.set_ylabel(\"Perplexity Score\")\n",
    "    ax1.grid()\n",
    "    \n",
    "    ax2 = fig.add_subplot(axgrid[0, 1])\n",
    "    ax2.plot(ks, coherences)\n",
    "    ax2.set_title(\"Number of topics vs Coherence Score\")\n",
    "    ax2.set_xlabel(\"Number of Topics\")\n",
    "    ax2.set_ylabel(\"Coherence Score\")\n",
    "    ax2.grid()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def full_model_test_loop(text, corpus, dictionary, ks=[1,5,10,20]):\n",
    "    # Run with a smaller, default set of ks first to reduce the range to search\n",
    "    perps = []\n",
    "    coherences = []\n",
    "    for k in ks:\n",
    "        ldamodel = models.ldamodel.LdaModel(corpus, num_topics=k, id2word=dictionary, passes=20, random_state=RANDOM_STATE)\n",
    "        scores = eval_model(ldamodel, text.tolist(), corpus, dictionary)\n",
    "        perps.append(scores[0])\n",
    "        coherences.append(scores[1])\n",
    "    plot_evals(perps, coherences, ks)"
   ],
   "id": "ffc8ece3411fbfe4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:01:50.214470Z",
     "start_time": "2025-05-09T18:01:50.210968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Run this to find the best k. Commented to save time. If the number of comments changes, this has to be rerun. Start with no k list.\n",
    "# print(\"Comments eval:\")\n",
    "# full_model_test_loop(preprocessed_comments, corpus_comments, dictionary_comments, [3,4,5,6,7]) # 1st run best around 5\n",
    "# print(\"Post Content eval:\")\n",
    "# full_model_test_loop(preprocessed_post_content, corpus_post_content, dictionary_post_content, [18,19,20,21,22]) # 1st run best around 20 (elbow)\n",
    "# print(\"Post Title eval:\")\n",
    "# full_model_test_loop(preprocessed_title, corpus_title, dictionary_title, [18,19,20,21,22]) # 1st run best around 20\n",
    "\n",
    "# 60-90 minutes."
   ],
   "id": "a346c5d2f3e50ae0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Topic Modeling",
   "id": "d7495206ee602d2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:01:50.242773Z",
     "start_time": "2025-05-09T18:01:50.239380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "k_comment = 5\n",
    "k_post_content = 21\n",
    "k_title = 20"
   ],
   "id": "314036e0a115c7b4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:10:20.442250Z",
     "start_time": "2025-05-09T18:01:50.268649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ldamodel_comments = models.ldamodel.LdaModel(corpus_comments, num_topics=k_comment, id2word=dictionary_comments, passes=20, random_state=RANDOM_STATE)\n",
    "ldamodel_post_content = models.ldamodel.LdaModel(corpus_post_content, num_topics=k_post_content, id2word=dictionary_post_content, passes=20, random_state=RANDOM_STATE)\n",
    "ldamodel_title = models.ldamodel.LdaModel(corpus_title, num_topics=k_title, id2word=dictionary_title, passes=20, random_state=RANDOM_STATE)\n",
    "\n",
    "# 8 min 30 sec"
   ],
   "id": "6dec4df67d883cf8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:11:59.575492Z",
     "start_time": "2025-05-09T18:10:26.623541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cp,cc = eval_model(ldamodel_comments, preprocessed_comments, corpus_comments, dictionary_comments)\n",
    "pcp, pcc = eval_model(ldamodel_post_content, preprocessed_post_content, corpus_post_content, dictionary_post_content)\n",
    "tp, tc = eval_model(ldamodel_title, preprocessed_title, corpus_title, dictionary_title)\n",
    "\n",
    "model_names = [\"comments\", \"post_content\", \"title\"]\n",
    "ks = [k_comment, k_post_content, k_title]\n",
    "ps = [cp, pcp, tp]\n",
    "cs = [cc, pcc, tc]\n",
    "labels = [\"Model\",\"K-value\",\"Perplexity\",\"Coherence\"]\n",
    "table = pd.DataFrame({\n",
    "    labels[0]: model_names,\n",
    "    labels[1]: ks,\n",
    "    labels[2]: ps,\n",
    "    labels[3]: cs,\n",
    "})\n",
    "table"
   ],
   "id": "b9d0b61ae41f9b30",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          Model  K-value  Perplexity  Coherence\n",
       "0      comments        5   -7.582630   0.617682\n",
       "1  post_content       21   -9.404658   0.476215\n",
       "2         title       20  -12.437024   0.523333"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>K-value</th>\n",
       "      <th>Perplexity</th>\n",
       "      <th>Coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comments</td>\n",
       "      <td>5</td>\n",
       "      <td>-7.582630</td>\n",
       "      <td>0.617682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>post_content</td>\n",
       "      <td>21</td>\n",
       "      <td>-9.404658</td>\n",
       "      <td>0.476215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>title</td>\n",
       "      <td>20</td>\n",
       "      <td>-12.437024</td>\n",
       "      <td>0.523333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:13:10.031891Z",
     "start_time": "2025-05-09T18:13:10.024266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Comment topics:\")\n",
    "ldamodel_comments.show_topics()"
   ],
   "id": "f0e5cfaa84ba6d46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment topics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.067*\"trump\" + 0.038*\"putin\" + 0.014*\"ukrain\" + 0.013*\"zelenski\" + 0.013*\"deal\" + 0.013*\"peac\" + 0.012*\"say\" + 0.011*\"presid\" + 0.010*\"said\" + 0.010*\"want\"'),\n",
       " (1,\n",
       "  '0.010*\"year\" + 0.010*\"like\" + 0.009*\"drone\" + 0.008*\"use\" + 0.007*\"time\" + 0.007*\"russian\" + 0.006*\"one\" + 0.006*\"also\" + 0.005*\"day\" + 0.005*\"bomb\"'),\n",
       " (2,\n",
       "  '0.038*\"ukrain\" + 0.038*\"russia\" + 0.019*\"war\" + 0.014*\"us\" + 0.014*\"russian\" + 0.011*\"gt\" + 0.011*\"would\" + 0.009*\"europ\" + 0.008*\"ukrainian\" + 0.007*\"crimea\"'),\n",
       " (3,\n",
       "  '0.034*\"nt\" + 0.020*\"like\" + 0.014*\"get\" + 0.014*\"would\" + 0.013*\"go\" + 0.012*\"know\" + 0.011*\"one\" + 0.011*\"think\" + 0.010*\"good\" + 0.009*\"russia\"'),\n",
       " (4,\n",
       "  '0.017*\"peopl\" + 0.015*\"russian\" + 0.012*\"nt\" + 0.009*\"like\" + 0.009*\"american\" + 0.009*\"countri\" + 0.007*\"one\" + 0.007*\"think\" + 0.006*\"us\" + 0.006*\"even\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:13:11.636319Z",
     "start_time": "2025-05-09T18:13:11.628218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Post content topics:\")\n",
    "ldamodel_post_content.show_topics()"
   ],
   "id": "f8308c939e5c1dda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post content topics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3,\n",
       "  '0.063*\"soldier\" + 0.031*\"wound\" + 0.029*\"gt\" + 0.027*\"hey\" + 0.025*\"one\" + 0.021*\"zelenskyy\" + 0.019*\"colombian\" + 0.017*\"kuzin\" + 0.015*\"drone\" + 0.014*\"kill\"'),\n",
       " (4,\n",
       "  '0.040*\"would\" + 0.032*\"stock\" + 0.029*\"member\" + 0.022*\"congress\" + 0.022*\"lawmak\" + 0.021*\"us\" + 0.020*\"fund\" + 0.020*\"elect\" + 0.020*\"act\" + 0.020*\"offic\"'),\n",
       " (8,\n",
       "  '0.041*\"fighter\" + 0.027*\"air\" + 0.024*\"forc\" + 0.022*\"product\" + 0.021*\"new\" + 0.018*\"aircraft\" + 0.016*\"close\" + 0.016*\"continu\" + 0.016*\"bomb\" + 0.013*\"reach\"'),\n",
       " (9,\n",
       "  '0.059*\"name\" + 0.027*\"like\" + 0.025*\"peopl\" + 0.023*\"would\" + 0.022*\"mean\" + 0.019*\"nt\" + 0.017*\"also\" + 0.014*\"someth\" + 0.012*\"case\" + 0.012*\"chatgpt\"'),\n",
       " (20,\n",
       "  '0.019*\"china\" + 0.018*\"weapon\" + 0.017*\"power\" + 0.017*\"use\" + 0.013*\"global\" + 0.013*\"would\" + 0.013*\"domin\" + 0.013*\"europ\" + 0.012*\"like\" + 0.011*\"someth\"'),\n",
       " (19,\n",
       "  '0.021*\"iran\" + 0.017*\"need\" + 0.017*\"could\" + 0.016*\"would\" + 0.016*\"one\" + 0.015*\"2024\" + 0.013*\"nation\" + 0.013*\"attack\" + 0.013*\"us\" + 0.012*\"netanyahu\"'),\n",
       " (2,\n",
       "  '0.062*\"amp\" + 0.028*\"advanc\" + 0.023*\"pictur\" + 0.018*\"ukrain\" + 0.018*\"formatpng\" + 0.018*\"autowebp\" + 0.018*\"side\" + 0.014*\"width1280\" + 0.014*\"troop\" + 0.013*\"back\"'),\n",
       " (17,\n",
       "  '0.019*\"gener\" + 0.019*\"ussr\" + 0.018*\"5\" + 0.018*\"want\" + 0.017*\"said\" + 0.015*\"2\" + 0.015*\"make\" + 0.014*\"sinc\" + 0.013*\"get\" + 0.012*\"wide\"'),\n",
       " (15,\n",
       "  '0.060*\"video\" + 0.046*\"sourc\" + 0.044*\"brutal\" + 0.042*\"realiti\" + 0.041*\"educ\" + 0.040*\"document\" + 0.040*\"intend\" + 0.039*\"war\" + 0.038*\"inform\" + 0.037*\"purpos\"'),\n",
       " (1,\n",
       "  '0.075*\"gt\" + 0.030*\"seat\" + 0.023*\"liber\" + 0.023*\"moscow\" + 0.017*\"deputi\" + 0.017*\"leader\" + 0.017*\"perform\" + 0.016*\"telegram\" + 0.015*\"north\" + 0.014*\"korean\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:19:32.480814500Z",
     "start_time": "2025-05-04T23:27:34.965586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Title topics:\")\n",
    "ldamodel_title.show_topics()"
   ],
   "id": "f99352b2466c1852",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title topics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  '0.133*\"russia\" + 0.082*\"hour\" + 0.078*\"fight\" + 0.065*\"offic\" + 0.062*\"time\" + 0.050*\"violat\" + 0.043*\"first\" + 0.042*\"offici\" + 0.034*\"admit\" + 0.032*\"troop\"'),\n",
       " (4,\n",
       "  '0.225*\"truce\" + 0.190*\"ceasefir\" + 0.078*\"ua\" + 0.074*\"sinc\" + 0.074*\"pov\" + 0.047*\"may\" + 0.041*\"announc\" + 0.026*\"territori\" + 0.022*\"includ\" + 0.018*\"order\"'),\n",
       " (19,\n",
       "  '0.119*\"claim\" + 0.078*\"air\" + 0.060*\"place\" + 0.058*\"back\" + 0.056*\"play\" + 0.048*\"within\" + 0.048*\"gener\" + 0.046*\"jet\" + 0.043*\"await\" + 0.040*\"true\"'),\n",
       " (15,\n",
       "  '0.105*\"attack\" + 0.093*\"moscow\" + 0.080*\"along\" + 0.072*\"join\" + 0.065*\"show\" + 0.049*\"pope\" + 0.049*\"nsfw\" + 0.046*\"negoti\" + 0.039*\"may\" + 0.034*\"9\"'),\n",
       " (11,\n",
       "  '0.099*\"trump\" + 0.081*\"peopl\" + 0.077*\"russia\" + 0.076*\"plan\" + 0.074*\"propos\" + 0.051*\"away\" + 0.046*\"reject\" + 0.045*\"one\" + 0.044*\"launch\" + 0.043*\"warn\"'),\n",
       " (18,\n",
       "  '0.245*\"putin\" + 0.128*\"war\" + 0.126*\"trump\" + 0.116*\"declar\" + 0.061*\"end\" + 0.048*\"call\" + 0.045*\"start\" + 0.033*\"donald\" + 0.032*\"say\" + 0.026*\"deal\"'),\n",
       " (9,\n",
       "  '0.080*\"right\" + 0.078*\"explos\" + 0.060*\"promis\" + 0.059*\"regim\" + 0.050*\"walk\" + 0.044*\"around\" + 0.043*\"car\" + 0.038*\"train\" + 0.027*\"chief\" + 0.027*\"us\"'),\n",
       " (17,\n",
       "  '0.105*\"russia\" + 0.087*\"rubio\" + 0.077*\"new\" + 0.071*\"fire\" + 0.054*\"think\" + 0.047*\"war\" + 0.041*\"would\" + 0.040*\"weapon\" + 0.039*\"sanction\" + 0.038*\"top\"'),\n",
       " (10,\n",
       "  '0.121*\"line\" + 0.095*\"soldier\" + 0.066*\"human\" + 0.065*\"armor\" + 0.063*\"hit\" + 0.042*\"injur\" + 0.040*\"insid\" + 0.036*\"near\" + 0.031*\"mine\" + 0.031*\"flag\"'),\n",
       " (12,\n",
       "  '0.379*\"‘\" + 0.122*\"stop\" + 0.085*\"putin\" + 0.051*\"tell\" + 0.039*\"latest\" + 0.034*\"integr\" + 0.031*\"famili\" + 0.031*\"polit\" + 0.018*\"european\" + 0.018*\"updat\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sentiment Analysis",
   "id": "b38d76ec33aa551a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:19:32.481811800Z",
     "start_time": "2025-05-04T23:28:22.060899Z"
    }
   },
   "cell_type": "code",
   "source": "#TODO plot histogram of scores, plot distribution of compound scores",
   "id": "2adad60b440bfdb7",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:19:32.482810500Z",
     "start_time": "2025-05-05T01:40:19.704715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def find_all_sentiments(document):\n",
    "    sentences = sent_tokenize(document)\n",
    "    document_scores = {\"pos\":0, \"neu\":0, \"neg\":0, \"compound\":0}\n",
    "    for sentence in sentences:\n",
    "        sentence_scores = sid.polarity_scores(sentence)\n",
    "        document_scores[\"compound\"] += sentence_scores[\"compound\"]\n",
    "        document_scores[\"neg\"] += sentence_scores[\"neg\"]\n",
    "        document_scores[\"neu\"] += sentence_scores[\"neu\"]\n",
    "        document_scores[\"pos\"] += sentence_scores[\"pos\"]    \n",
    "    num_sent = len(sentences)\n",
    "    document_scores[\"compound\"] /= num_sent\n",
    "    document_scores[\"neg\"] /= num_sent\n",
    "    document_scores[\"neu\"] /= num_sent\n",
    "    document_scores[\"pos\"] /= num_sent\n",
    "    return document_scores\n",
    "\n",
    "\n",
    "    \n",
    "def find_all_topic_sentiments(corp, documents, model):\n",
    "    dominant_topics = []\n",
    "    document_scores = []\n",
    "    corpdoc = zip(corp, documents) # Link each corpus \"bag\" representation with the full document\n",
    "    for bag, document in corpdoc:\n",
    "        topics = model.get_document_topics(bag)\n",
    "        dominant_topic = max(topics, key=lambda x: x[1])[0]\n",
    "        dominant_topics.append(dominant_topic)\n",
    "        document_scores.append(find_all_sentiments(document))\n",
    "        \n",
    "    document_scores_df = pd.DataFrame(document_scores) # Each set of sentiments represents a document\n",
    "    document_scores_df[\"text\"] = documents.reset_index(drop=True) # Ensure alignment and drop nans\n",
    "    document_scores_df[\"topic\"] = dominant_topics # Also add the dominant topic\n",
    "    \n",
    "    topic_sentiments = document_scores_df.groupby(\"topic\")[[\"pos\",\"neu\",\"neg\",\"compound\"]].mean()\n",
    "        \n",
    "    return topic_sentiments, document_scores_df.drop(\"topic\", axis=1)"
   ],
   "id": "f69da25e1750478b",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#TODO Index alignment to ensure df text and scores are aligned",
   "id": "963aa925971688a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:19:32.482810500Z",
     "start_time": "2025-05-05T01:40:24.334278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clean_comments = clean_column(df_recent, \"self_text\")[\"self_text\"]\n",
    "comment_topic_sentiments, comment_document_sentiments = find_all_topic_sentiments(corpus_comments, clean_comments, ldamodel_comments)\n",
    "# 3 minutes"
   ],
   "id": "332401e1cfd1b731",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:19:32.483806800Z",
     "start_time": "2025-05-05T01:43:43.113671Z"
    }
   },
   "cell_type": "code",
   "source": "comment_document_sentiments",
   "id": "cfea6f35518f4902",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          pos       neu       neg  compound  \\\n",
       "0      0.2140  0.726000  0.060000  0.557400   \n",
       "1      0.4170  0.583000  0.000000  0.753500   \n",
       "2      0.2660  0.660667  0.073333  0.249300   \n",
       "3      0.0000  0.962750  0.037250 -0.096625   \n",
       "4      0.0528  0.835800  0.111350 -0.139580   \n",
       "...       ...       ...       ...       ...   \n",
       "38166  0.3100  0.690000  0.000000  0.202300   \n",
       "38167  0.0000  1.000000  0.000000  0.000000   \n",
       "38168  0.1750  0.755000  0.070000  0.255300   \n",
       "38169  0.0000  0.328000  0.672000 -0.624900   \n",
       "38170  0.0895  0.795000  0.115500 -0.142450   \n",
       "\n",
       "                                                    text  \n",
       "0      I'd have to agree that it's hard to shop for m...  \n",
       "1      They don't, so you don't have to worry about t...  \n",
       "2      Trump is just buying time.  He won't do shit t...  \n",
       "3      They are being randomly called up for military...  \n",
       "4      Most of your assumptions here are wrong.\\n\\nFi...  \n",
       "...                                                  ...  \n",
       "38166                                                NaN  \n",
       "38167                                                NaN  \n",
       "38168                                                NaN  \n",
       "38169                                                NaN  \n",
       "38170                                                NaN  \n",
       "\n",
       "[38171 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "      <th>neg</th>\n",
       "      <th>compound</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.726000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.557400</td>\n",
       "      <td>I'd have to agree that it's hard to shop for m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4170</td>\n",
       "      <td>0.583000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.753500</td>\n",
       "      <td>They don't, so you don't have to worry about t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2660</td>\n",
       "      <td>0.660667</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.249300</td>\n",
       "      <td>Trump is just buying time.  He won't do shit t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.962750</td>\n",
       "      <td>0.037250</td>\n",
       "      <td>-0.096625</td>\n",
       "      <td>They are being randomly called up for military...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.835800</td>\n",
       "      <td>0.111350</td>\n",
       "      <td>-0.139580</td>\n",
       "      <td>Most of your assumptions here are wrong.\\n\\nFi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38166</th>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38167</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38168</th>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38169</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>-0.624900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38170</th>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.115500</td>\n",
       "      <td>-0.142450</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38171 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:19:32.484803800Z",
     "start_time": "2025-05-05T01:44:32.995680Z"
    }
   },
   "cell_type": "code",
   "source": "clean_column(df_recent, \"self_text\")[\"self_text\"]",
   "id": "2bd594f6bf815270",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:19:32.484803800Z",
     "start_time": "2025-05-05T01:43:43.645343Z"
    }
   },
   "cell_type": "code",
   "source": "comment_topic_sentiments",
   "id": "811fecc89ffe11f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            pos       neu       neg  compound\n",
       "topic                                        \n",
       "0      0.066210  0.814469  0.106611 -0.066809\n",
       "1      0.109539  0.766219  0.120293 -0.036291\n",
       "2      0.140546  0.677626  0.169508 -0.039746\n",
       "3      0.155080  0.668022  0.161753 -0.053668\n",
       "4      0.120145  0.768581  0.106382  0.014652\n",
       "5      0.110581  0.764752  0.119601 -0.022583\n",
       "6      0.145910  0.741989  0.103407  0.036854\n",
       "7      0.087981  0.805794  0.100890 -0.046051\n",
       "8      0.109032  0.802655  0.085213  0.030286\n",
       "9      0.091021  0.805793  0.099886 -0.029056"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "      <th>neg</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066210</td>\n",
       "      <td>0.814469</td>\n",
       "      <td>0.106611</td>\n",
       "      <td>-0.066809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.109539</td>\n",
       "      <td>0.766219</td>\n",
       "      <td>0.120293</td>\n",
       "      <td>-0.036291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.140546</td>\n",
       "      <td>0.677626</td>\n",
       "      <td>0.169508</td>\n",
       "      <td>-0.039746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.155080</td>\n",
       "      <td>0.668022</td>\n",
       "      <td>0.161753</td>\n",
       "      <td>-0.053668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120145</td>\n",
       "      <td>0.768581</td>\n",
       "      <td>0.106382</td>\n",
       "      <td>0.014652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.110581</td>\n",
       "      <td>0.764752</td>\n",
       "      <td>0.119601</td>\n",
       "      <td>-0.022583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.145910</td>\n",
       "      <td>0.741989</td>\n",
       "      <td>0.103407</td>\n",
       "      <td>0.036854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.087981</td>\n",
       "      <td>0.805794</td>\n",
       "      <td>0.100890</td>\n",
       "      <td>-0.046051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.109032</td>\n",
       "      <td>0.802655</td>\n",
       "      <td>0.085213</td>\n",
       "      <td>0.030286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.091021</td>\n",
       "      <td>0.805793</td>\n",
       "      <td>0.099886</td>\n",
       "      <td>-0.029056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
